<!doctype html><html xmlns=http://www.w3.org/1999/xhtml xml:lang=en lang=en-us><head><meta name=generator content="Hugo 0.64.0"><link href=http://gmpg.org/xfn/11 rel=profile><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><title>Dash &#183; Dash</title><link rel=stylesheet href=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap-theme.min.css><link rel=stylesheet href="https://purplepalmdash.github.io/css/poole.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/hyde.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/poole-overrides.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/hyde-overrides.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/hyde-a.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/custom-additions.css?ref=abc124"><link rel=stylesheet href=https://purplepalmdash.github.io/css/highlight/googlecode.css><link rel=stylesheet href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.3.0/css/font-awesome.min.css><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.5/styles/docco.min.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/1.10.2/jquery.min.js></script><script type=text/javascript src=/js/html2canvas.js></script><script type=text/javascript>function genPostShot(){var rightNow=new Date();var imageName=rightNow.toISOString().slice(0,16).replace(/(-)|(:)|(T)/g,"");imageName+='.jpg'
html2canvas(document.getElementsByClassName('post'),{background:'#FFFFFF',onrendered:function(canvas){$('#test').attr('href',canvas.toDataURL("image/jpeg"));$('#test').attr('download',imageName);$('#test')[0].click();}});};</script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.5/highlight.min.js></script><script>hljs.initHighlightingOnLoad();</script><link rel=apple-touch-icon-precomposed sizes=144x144 href="http://purplepalmdash.github.io/touch-icon-144-precomposed.png?ref=abc124"><link href="http://purplepalmdash.github.io/favicon.png?ref=abc124" rel=icon><link href=%7balternate%20%7bRSS%20application/rss+xml%20%20index%20alternate%20%20false%20false%20true%20false%20false%200%7d%20/index.xml%20http://purplepalmdash.github.io/index.xml%7d rel=alternate type=application/rss+xml title="Dash &#183; Dash"><meta name=description content><meta name=keywords content="unix,virtualization,embedded,linux"></head><body class=theme-base-0c><div class=sidebar><div class="container sidebar-sticky"><div class=sidebar-about><img src=http://purplepalmdash.github.io/images/mylogo.jpeg alt=gravatar><h1><a href=http://purplepalmdash.github.io/>很惭愧，就做了一点微小的工作</a></h1><a href=http://purplepalmdash.github.io/><p>Dash</p></a></div><ul class=sidebar-nav><li class=sidebar-nav-item><a href=http://purplepalmdash.github.io/post/>All Posts</a></li><li class=sidebar-nav-item><a href=http://purplepalmdash.github.io/categories/technology/>Technology</a></li><li class=sidebar-nav-item><a href=http://purplepalmdash.github.io/categories/life/>Life</a></li><li class=sidebar-nav-item><a href=http://purplepalmdash.github.io/categories/linuxtips/>LinuxTips</a></li></ul><ul class=sidebar-nav><li class=sidebar-nav-item><a href=https://github.com/purplepalmdash><i class="fa fa-github-square fa-3x"></i></a><a href=https://cn.linkedin.com/in/yang-feipeng-1b909319><i class="fa fa-linkedin-square fa-3x"></i></a><a href=https://plus.google.com/u/0/106572959364703833986><i class="fa fa-google-plus-square fa-3x"></i></a><a href=https://www.facebook.com/yang.feipeng><i class="fa fa-facebook-square fa-3x"></i></a><a href=https://twitter.com/dashwillfly><i class="fa fa-twitter-square fa-3x"></i></a></li></ul></div></div><div class="content container"><div class=posts><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/blog/2019/12/19/kubespray2.12.0%E7%A6%BB%E7%BA%BF%E5%8C%96%E6%89%8B%E8%AE%B0/>kubespray2.12.0离线化手记</a></h1><span class=post-date>Dec 19, 2019<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><h3 id=steps>Steps</h3><p>Download the source code:</p><pre><code># wget https://github.com/kubernetes-sigs/kubespray/archive/v2.12.0.tar.gz
</code></pre><p>Install ansible via old Rong/.</p><pre><code>$ scp -r Rong test@192.168.121.104:/home/test/
$ cd ~/Rong
$ sudo mv /etc/apt/sources.list /home/test/
$ sudo ./bootstrap.sh
$ sudo mv /home/test/sources.list /etc/apt/
</code></pre><p>Change options:</p><pre><code>$ cd ~/kubespray-2.12.0
$ cp ../deploy.key .
$ ssh -i deploy.key root@192.168.121.104
$ exit
$ cp -rfp inventory/sample/ inventory/rong
$ vim inventory/rong/hosts.ini
[all]
kubespray ansible_host=192.168.121.104 ansible_ssh_user=root ansible_ssh_private_key_file=./deploy.key  ip=192.168.121.104

[kube-master]
kubespray

[etcd]
kubespray

[kube-node]
kubespray

[k8s-cluster:children]
kube-master
kube-node
</code></pre><p>Add some configuration:</p><pre><code>$ vim group_vars/k8s-cluster/addons.yml 
dashboard_enabled: true
helm_enabled: true
metrics_server_enabled: true
</code></pre><h3 id=speedup>Speedup</h3><p>cross the gfw, host machine side:</p><pre><code>$ sudo iptables -t nat -A PREROUTING -p tcp -s 192.168.121.0/24 -j DNAT --to-destination 127.0.0.1:12345
$ sudo sysctl -w net.ipv4.conf.all.route_localnet=1
</code></pre><p>vm side:</p><pre><code>$ sudo vim /etc/resolv.conf
nameserver 223.5.5.5
nameserver 8.8.8.8
</code></pre><h3 id=setup-cluster>Setup Cluster</h3><p>Via:</p><pre><code>$ ansible-playbook -i inventory/rong/hosts.ini cluster.yml
</code></pre><h3 id=fetch-things>Fetch things</h3><p>Get all of the images:</p><pre><code># docker pull xueshanf/install-socat:latest
# docker images | sed -n '1!p' | awk {'print $1&quot;:&quot;$2'} | tr '\n' ' '
nginx:1.17 gcr.io/google-containers/k8s-dns-node-cache:1.15.8 gcr.io/google-containers/kube-proxy:v1.16.3 gcr.io/google-containers/kube-apiserver:v1.16.3 gcr.io/google-containers/kube-controller-manager:v1.16.3 gcr.io/google-containers/kube-scheduler:v1.16.3 lachlanevenson/k8s-helm:v2.16.1 gcr.io/kubernetes-helm/tiller:v2.16.1 coredns/coredns:1.6.0 calico/node:v3.7.3 calico/cni:v3.7.3 calico/kube-controllers:v3.7.3 gcr.io/google_containers/metrics-server-amd64:v0.3.3 gcr.io/google-containers/cluster-proportional-autoscaler-amd64:1.6.0 gcr.io/google_containers/kubernetes-dashboard-amd64:v1.10.1 quay.io/coreos/etcd:v3.3.10 gcr.io/google-containers/addon-resizer:1.8.3 gcr.io/google-containers/pause:3.1 gcr.io/google_containers/pause-amd64:3.1 xueshanf/install-socat:latest
# docker save -o k8simages.tar nginx:1.17 gcr.io/google-containers/k8s-dns-node-cache:1.15.8 gcr.io/google-containers/kube-proxy:v1.16.3 gcr.io/google-containers/kube-apiserver:v1.16.3 gcr.io/google-containers/kube-controller-manager:v1.16.3 gcr.io/google-containers/kube-scheduler:v1.16.3 lachlanevenson/k8s-helm:v2.16.1 gcr.io/kubernetes-helm/tiller:v2.16.1 coredns/coredns:1.6.0 calico/node:v3.7.3 calico/cni:v3.7.3 calico/kube-controllers:v3.7.3 gcr.io/google_containers/metrics-server-amd64:v0.3.3 gcr.io/google-containers/cluster-proportional-autoscaler-amd64:1.6.0 gcr.io/google_containers/kubernetes-dashboard-amd64:v1.10.1 quay.io/coreos/etcd:v3.3.10 gcr.io/google-containers/addon-resizer:1.8.3 gcr.io/google-containers/pause:3.1 gcr.io/google_containers/pause-amd64:3.1 xueshanf/install-socat:latest; xz -T4 k8simages.tar
</code></pre><p>Get debs:</p><pre><code># mkdir /home/test/debs
# find . | grep deb$ | xargs -I % cp % /home/test/debs/
</code></pre><p>Get temp files:</p><pre><code># ls /tmp/releases/
calicoctl                           images/                             kubectl-v1.16.3-amd64               
cni-plugins-linux-amd64-v0.8.1.tgz  kubeadm-v1.16.3-amd64               kubelet-v1.16.3-amd64     
# cp /tmp/releases/* /home/test/file/
</code></pre><h3 id=more-pkgs>More pkgs</h3><p>Use the old deb repository for installing ansible:</p><pre><code>$ cp old_1804debs.tar.xz ~/YourWebServer
$ tar xJvf old_1804debs.tar.xz
$ sudo vim /etc/apt/sources.list
deb [trusted=yes]  http://192.168.122.1/ansible_bionic ./
$ sudo apt-get update -y &amp;&amp; sudo DEBIAN_FRONTEND=noninteractive apt-get install -y ansible python-netaddr
</code></pre><p>more pkgs should be installed manually and copy to <code>/root/debs</code>:</p><pre><code># apt-get install -y iputils-ping nethogs python-netaddr build-essential bind9 bind9utils nfs-common nfs-kernel-server ntpdate ntp tcpdump iotop unzip wget apt-transport-https socat rpcbind arping fping python-apt ipset ipvsadm pigz nginx docker-registry
# cd /root/debs
# wget http://209.141.35.192/netdata_1.18.1_amd64_bionic.deb
# apt-get install  ./netdata_1.18.1_amd64_bionic.deb
# find /var/cache | grep deb$ | xargs -I % cp % ./
# dpkg-scanpackages . /dev/null | gzip -9c &gt; Packages.gz
</code></pre><h3 id=offline-registry-setup>Offline registry setup</h3><p>On a running secureregistry server do following:</p><pre><code># systemctl stop secureregistryserver
# cd /opt/local/secureregistryserver/
# mv data data.back
# docker-compose up
# docker push xxxxx
</code></pre><p>Your docker push item is listed as(v1.16.3):</p><pre><code>docker push gcr.io/google-containers/k8s-dns-node-cache:1.15.8
docker push gcr.io/google-containers/kube-proxy:v1.16.3
docker push gcr.io/google-containers/kube-apiserver:v1.16.3
docker push gcr.io/google-containers/kube-controller-manager:v1.16.3
docker push gcr.io/google-containers/kube-scheduler:v1.16.3
docker push lachlanevenson/k8s-helm:v2.16.1
docker push gcr.io/kubernetes-helm/tiller:v2.16.1
docker push coredns/coredns:1.6.0
docker push calico/node:v3.7.3
docker push calico/cni:v3.7.3
docker push calico/kube-controllers:v3.7.3
docker push gcr.io/google_containers/metrics-server-amd64:v0.3.3
docker push gcr.io/google-containers/cluster-proportional-autoscaler-amd64:1.6.0
docker push gcr.io/google_containers/kubernetes-dashboard-amd64:v1.10.1
docker push quay.io/coreos/etcd:v3.3.10
docker push gcr.io/google-containers/addon-resizer:1.8.3
docker push gcr.io/google-containers/pause:3.1
docker push gcr.io/google_containers/pause-amd64:3.1
docker push xueshanf/install-socat:latest
docker push nginx:1.17
</code></pre><p>tar docker.tar.gz:</p><pre><code># cd /opt/local/secureregistryserver/data
# tar czvf docker.tar.gz docker/

</code></pre><h3 id=upgrade>Upgrade</h3><p>From v1.15.3 to v1.16.3, steps:</p><pre><code>$ pwd
0_preinstall/roles/kube-deploy/files
$ ls
1604debs.tar.xz  1804debs.tar.xz  calicoctl-linux-amd64  cni-plugins-linux-amd64-v0.8.1.tgz  dns  docker-compose  docker.tar.gz  dockerDebs.tar.gz  gpg  hyperkube  kubeadm  nginx  ntp.conf
</code></pre><p>Generate 1804debs.tar.xz and replace:</p><pre><code># cp -r /root/debs ./Rong
# tar cJvf 1804debs.tar.xz Rong
</code></pre><p>Calculate calicoctl/ , it&rsquo;s the same md5, so needn&rsquo;t replacement.</p><p><code>docker.tar.gz</code> should be replaced with the newer one.</p><p>Docker version upgradeed to 19.03.5, so we need to replace the old ones.</p><pre><code># tar xzvf dockerDebs.tar.gz  -C tmp/
ubuntu/dists/bionic/pool/stable/amd64/containerd.io_1.2.10-2_amd64.deb
ubuntu/dists/bionic/pool/stable/amd64/docker-ce-cli_19.03.3~3-0~ubuntu-bionic_amd64.deb
ubuntu/dists/bionic/pool/stable/amd64/docker-ce_18.09.7~3-0~ubuntu-bionic_amd64.deb
</code></pre><p>apt-mirror for syncing on internet:</p><pre><code>$ sudo vim /etc/apt/mirror.list
set base_path    /media/sda/tmp/apt-mirror
set nthreads     20
set _tilde 0
deb https://download.docker.com/linux/ubuntu bionic stable
deb https://download.docker.com/linux/ubuntu xenial stable
$ sudo apt-mirror

</code></pre><p>Too slow for the fucking gfw!!!</p><p>After apt-mirror, we have to rsync using following command:</p><pre><code>$ pwd
/media/sda/tmp/apt-mirror/mirror/download.docker.com/linux/ubuntu
$ ls
dists
$ rsync -a -e 'ssh -p 2345 ' --progress dists/ root@192.168.111.11:/destination/ubuntu/dists/
</code></pre><p>wget the gpg file:</p><pre><code>$ wget https://download.docker.com/linux/ubuntu/gpg
$ tar czvf dockerDebs.tar.gz gpg ubuntu/
$ ls -l -h dockerDebs.tar.gz
-rw-r--r-- 1 root root 144M Dec 23 17:41 dockerDebs.tar.gz
$ cp dockerDebs.tar.gz ~/0_preinstall/roles/kube-deploy/files
</code></pre><p>Binary replacement:</p><pre><code>previsous:    
 hyperkube  kubeadm  
current:    
kubeadm-v1.16.3-amd64 kubectl-v1.16.3-amd64 kubelet-v1.16.3-amd64
</code></pre><p>Edit the file, since in v1.16.3 we didn&rsquo;t use hyperkube:</p><pre><code>$ vim deploy-ubuntu/tasks/main.yml
  - name: &quot;upload static files to /usr/local/static&quot;
    copy:
      src: &quot;{{ item }}&quot;
      dest: /usr/local/static/
      owner: root
      group: root
      mode: 0777
    with_items:
      #- files/hyperkube
      - files/calicoctl-linux-amd64
      - files/kubeadm-v1.16.3-amd64
      - files/kubectl-v1.16.3-amd64
      - files/kubelet-v1.16.3-amd64
      #- files/kubeadm
      - files/cni-plugins-linux-amd64-v0.8.1.tgz
      #- files/dockerDebs.tar.gz
      - files/gpg
</code></pre><p>Add sysctl items:</p><pre><code># vim ./roles/kubernetes/preinstall/tasks/0080-system-configurations.yml
- name: set fs inotify.max_user_watches to 1048576
  sysctl:
    sysctl_file: &quot;{{ sysctl_file_path }}&quot;
    name: fs.inotify.max_user_watches
    value: 1048576
    state: present
    reload: yes
</code></pre><p>Added some files like <code>./roles/kubernetes/preinstall/tasks/0000-xxx-ubuntu.yml</code>, minimum modifications to kubespray source code, you can use bcompare for viewing.</p></div><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/blog/2019/12/11/workingtipsonkubespraykongfuzi/>WorkingTipsOnKubesprayKongFuZi</a></h1><span class=post-date>Dec 11, 2019<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><h3 id=目的>目的</h3><p>Kubespray在离线环境下，完全不考虑包管理、docker升级的发行版。</p><h3 id=技术要点>技术要点</h3><ol><li>离线情况下的源仓库准备。</li><li>完全离线情况下ansible的执行。</li></ol><h3 id=环境准备与本文无关>环境准备(与本文无关)</h3><p>Ubuntu 16.04.2， 最小化安装后，做成vagrant box:</p><pre><code>$ sudo vim /etc/default/grub
GRUB_CMDLINE_LINUX_DEFAULT=&quot;quiet&quot;
GRUB_CMDLINE_LINUX=&quot;net.ifnames=0 biosdevname=0&quot;
$ sudo grub-mkconfig -o /boot/grub/grub.cfg
$ sudo useradd -m vagrant
$ sudo passwd vagrant
Enter new UNIX password:
Retype new UNIX password:
passwd: password updated successfully
$ sudo mkdir -p /home/vagrant/.ssh
$ sudo chmod 0700 /home/vagrant/.ssh/
$ sudo vim /home/vagrant/.ssh/authorized_keys
$ sudo cat /home/vagrant/.ssh//authorized_keys
ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEA6NF8iallvQVp22WDkTkyrtvp9eWW6A8YVr+kz4TjGYe7gHzIw+niNltGEFHzD8+v1I2YJ6oXevct1YeS0o9HZyN1Q9qgCgzUFtdOKLv6IedplqoPkcmF0aYet2PkEDo3MlTBckFXPITAMzF8dJSIFo9D8HfdOV0IAdx4O7PtixWKn5y2hMNG0zQPyUecp4pzC6kivAIhyfHilFR61RGL+GPXQ2MWZWFYbAGjyiYJnAmCP3NOTd0jMZEnDkbUvxhMmBYSdETk1rRgm+R4LOzFUGaHqHDLKLX+FIPKcF96hrucXzcWyLbIbEgE98OHlnVYCzRdK8jlqm8tehUc9c9WhQ== vagrant insecure public key
$ sudo chown -R vagrant /home/vagrant/.ssh
$ sudo cp /home/test/.bashrc /home/vagrant/.bashrc 
$ sudo cp /home/test/.bash_logout /home/vagrant/.bash_logout
$ sudo cp /home/test/.profile /home/vagrant/.profile
$ sudo vim /home/vagrant/.profile 
add
[ -z &quot;$BASH_VERSION&quot; ] &amp;&amp; exec /bin/bash -l
$ sudo chsh -s /bin/bash vagrant
$ sudo  vim /etc/ssh/sshd_config 
AuthorizedKeysFile .ssh/authorized_keys
$ sudo visudo -f /etc/sudoers.d/vagrant
vagrant ALL=(ALL) NOPASSWD:ALL
Defaults:vagrant !requiretty
$ sudo vim /etc/network/interfaces
change from ens3 to eth0
auto eth0
inet .....
</code></pre><p>关闭机器后，缩减磁盘空间编辑vagrantfile文件并最终创建box:</p><pre><code>$ sudo qemu-img convert -c -O qcow2  ubuntu160402.qcow2 ubuntu160402Shrink.qcow2
$ sudo vim metadata.json
{
&quot;provider&quot;     : &quot;libvirt&quot;,
&quot;format&quot;       : &quot;qcow2&quot;,
&quot;virtual_size&quot; : 80
}
$ sudo vim Vagrantfile
Vagrant.configure(&quot;2&quot;) do |config|
       config.vm.provider :libvirt do |libvirt|
       libvirt.driver = &quot;kvm&quot;
       libvirt.host = 'localhost'
       libvirt.uri = 'qemu:///system'
       end
config.vm.define &quot;new&quot; do |custombox|
       custombox.vm.box = &quot;custombox&quot;
       custombox.vm.provider :libvirt do |test|
       test.memory = 1024
       test.cpus = 1
       end
       end
end
$ sudo tar cvzf custom_box.box ./metadata.json ./Vagrantfile ./box.img
</code></pre><p>添加并检查box是否可用:</p><pre><code>$ vagrant box add custom_box.box --name &quot;ubuntu160402old&quot;
$ vagrant init ubuntu160402old
$ vagrant up --provider=libvirt
</code></pre><h3 id=server实现>Server实现</h3><p>沿用coreos的机制，将docker/docker-compose以二进制的方式安装。安装完毕后通过容器启动几乎所有的服务:</p><pre><code>ntp
harbor
ansible
dnsmasq
fileserver
</code></pre></div><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/blog/2019/12/09/quickstartofvagrantandansible/>QuickStartOfVagrantAndAnsible</a></h1><span class=post-date>Dec 9, 2019<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><h3 id=setup-environment>Setup Environment</h3><p>Using <code>vagrant box list</code> for getting all of the boxes, then initiate the environment via(take <code>rhel74</code> box for example):</p><pre><code>$ vagrant init rhel74
</code></pre><p>Add the cpus/memory customization values:</p><pre><code>  config.vm.provider &quot;libvirt&quot; do |vb|
     vb.memory = &quot;4096&quot;
     vb.cpus = &quot;4&quot;
  end
</code></pre><p>Disable the rsync folder:</p><pre><code>  config.vm.synced_folder &quot;.&quot;, &quot;/vagrant&quot;, disabled: true, type: &quot;rsync&quot;, rsync__args: ['--verbose', '--archive', '--delete', '-z'] , rsync__exclude: ['.git','venv']
</code></pre><p>Add ansible deployment:</p><pre><code>  config.vm.provision &quot;ansible&quot; do |ansible|
    ansible.playbook = &quot;playbook.yml&quot;
    ansible.become = true
  end
</code></pre><p>your playbook.yml should like following:</p><pre><code>---
- hosts: all
  gather_facts: false
  become: True
  tasks:
    - name: &quot;Run shell for provision&quot;
      shell: mkdir -p /root/tttt
</code></pre><h3 id=manually-run-ansible-playbook>Manually Run ansible playbook</h3><p>vagrant will create the inventory files under the <code>.vagrant</code> folder:</p><pre><code>cat .vagrant/provisioners/ansible/inventory/vagrant_ansible_inventory 
# Generated by Vagrant

default ansible_host=192.168.121.215 ansible_port=22 ansible_user='vagrant' ansible_ssh_private_key_file='/media/sda/Code/vagrant/dockerOnrhel74/.vagrant/machines/default/libvirt/private_key'

</code></pre><p>Then you could run the provision task like:</p><pre><code>$ ansible-playbook -i .vagrant/provisioners/ansible/inventory/vagrant_ansible_inventory playbook.yml
</code></pre></div><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/blog/2019/12/06/%E7%94%A8terraform%E7%AE%A1%E7%90%86%E9%9B%86%E7%BE%A4%E7%BC%96%E8%AF%91%E7%8E%AF%E5%A2%83-2/>用Terraform管理集群编译环境-2</a></h1><span class=post-date>Dec 6, 2019<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><p>前面已经用terraform可以批量创建出基础环境，但真正要做到集群部署这个环节还是需要有一定的活需要做的。所以后续我将terraform和自己改编的rong揉在了一起。通过预编译好的qcow2镜像，可以快速启动任意个kubernetes节点的集群。</p><h3 id=前置条件>前置条件</h3><p>qcow2预编译镜像中需安装<code>cloud-init</code>, <code>qemu-guest-agent</code>两个包。安装完毕后需手动使能<code>cloud-init</code>，后续我们在terraform创建虚拟机实例的时候可以通过cloud-init注入一些信息。</p><pre><code># systemctl enable cloud-init
</code></pre><p>debian 9.0上需要安装mkisofs, 因为mkisofs已被genisoimage代替，因而需执行以下操作:</p><pre><code># apt-get install -y genisoimage
# ln -s /usr/bin/genisoimage /usr/bin/mkisofs
</code></pre><p>terraform需要具备以下插件, 其中terraform-provider-libvirt在debian 9.0上需手动编译:</p><pre><code># ls ~/.terraform.d/plugins/
terraform-provider-ansible  terraform-provider-libvirt  terraform-provider-template_v2.1.2_x4
</code></pre><h3 id=cloud-init文件>cloud-init文件</h3><p><code>cloud-init.cfg</code>文件内容如下:</p><pre><code>#cloud-config
# https://cloudinit.readthedocs.io/en/latest/topics/modules.html
hostname: ${HOSTNAME}
users:
  - name: xxxxx
    sudo: ALL=(ALL) NOPASSWD:ALL
    groups: users, admin
    home: /home/xxxxx
    shell: /bin/bash
    ssh-authorized-keys:
      - ssh-rsa xxxxxxxxxxxxxxxxxxxx
ssh_pwauth: True
disable_root: false
chpasswd:
  list: |
     xxxxx:linux
  expire: False
</code></pre><p>真正用到的只有<code>hostname: ${HOSTNAME}</code>这个变量，其他的步骤是用于创建一个名为<code>xxxxx</code>的用户并更改其密码。后续需要对操作系统进行深度定制的时候可以使用该操作。</p><h3 id=maintf定义>main.tf定义</h3><p><code>main.tf</code>是整个底层架构编排的核心文件，内容如下:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>bash <span style=color:#f92672>{</span>linenos<span style=color:#f92672>=</span>table,linenostart<span style=color:#f92672>=</span>1<span style=color:#f92672>}</span>
<span style=color:#75715e>################################################################################</span>
<span style=color:#75715e>#  vars definition</span>
<span style=color:#75715e>################################################################################</span>
variable <span style=color:#e6db74>&#34;VM_COUNT&#34;</span> <span style=color:#f92672>{</span>
  default <span style=color:#f92672>=</span> <span style=color:#ae81ff>10</span>
  type <span style=color:#f92672>=</span> number
<span style=color:#f92672>}</span>

variable <span style=color:#e6db74>&#34;VM_USER&#34;</span> <span style=color:#f92672>{</span>
  default <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;developer&#34;</span>
  type <span style=color:#f92672>=</span> string
<span style=color:#f92672>}</span>

variable <span style=color:#e6db74>&#34;VM_HOSTNAME&#34;</span> <span style=color:#f92672>{</span>
  default <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;newnode&#34;</span>
  type <span style=color:#f92672>=</span> string
<span style=color:#f92672>}</span>

variable <span style=color:#e6db74>&#34;VM_IMG_URL&#34;</span> <span style=color:#f92672>{</span>
  default <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;http://1xx.xxx.xxx.xxx/xxxx180403cloudinit.img&#34;</span>
  type <span style=color:#f92672>=</span> string
<span style=color:#f92672>}</span>

variable <span style=color:#e6db74>&#34;VM_IMG_FORMAT&#34;</span> <span style=color:#f92672>{</span>
  default <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;qcow2&#34;</span>
  type <span style=color:#f92672>=</span> string
<span style=color:#f92672>}</span>

<span style=color:#75715e># https://www.ipaddressguide.com/cidr</span>
variable <span style=color:#e6db74>&#34;VM_CIDR_RANGE&#34;</span> <span style=color:#f92672>{</span>
  default <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;10.10.10.0/24&#34;</span>
  type <span style=color:#f92672>=</span> string
<span style=color:#f92672>}</span>

variable <span style=color:#e6db74>&#34;LIBVIRT_POOL_DIR&#34;</span> <span style=color:#f92672>{</span>
  default <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;./.local/.docker-libvirt&#34;</span>
  type <span style=color:#f92672>=</span> string
<span style=color:#f92672>}</span>

<span style=color:#75715e>#variable libvirt_host {</span>
<span style=color:#75715e>#  type = string</span>
<span style=color:#75715e>#  description = &#34;IP address of host running libvirt&#34;</span>
<span style=color:#75715e>#}</span>
#
<span style=color:#75715e>#variable instance_name {</span>
<span style=color:#75715e>#  type = string</span>
<span style=color:#75715e>#  description = &#34;name of VM instance&#34;</span>
<span style=color:#75715e>#}</span>

variable pool_name <span style=color:#f92672>{</span>
  type <span style=color:#f92672>=</span> string
  default <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;default&#34;</span>
  description <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;name of pool to store disk and iso image&#34;</span>
<span style=color:#f92672>}</span>

<span style=color:#75715e>#variable source_path {</span>
<span style=color:#75715e>#  type = string</span>
<span style=color:#75715e>#  description = &#34;path to qcow2 base image, can be remote url or local disk path&#34;</span>
<span style=color:#75715e>#}</span>

variable disk_format <span style=color:#f92672>{</span>
  type <span style=color:#f92672>=</span> string
  default <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;qcow2&#34;</span>
<span style=color:#f92672>}</span>

variable default_password <span style=color:#f92672>{</span>
  type <span style=color:#f92672>=</span> string
  default <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;passw0rd&#34;</span>
  description <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;default password to login to VM when running, it&#39;s recommended to disable this manually&#34;</span>
<span style=color:#f92672>}</span>

variable memory_size <span style=color:#f92672>{</span>
  type <span style=color:#f92672>=</span> string
  default <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;5120&#34;</span>
  description <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;memory size of VM&#34;</span>
<span style=color:#f92672>}</span>

variable num_cpu <span style=color:#f92672>{</span>
  default <span style=color:#f92672>=</span> <span style=color:#ae81ff>2</span>
  description <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;number of vCPU which VM has&#34;</span>
<span style=color:#f92672>}</span>

variable num_network_interface <span style=color:#f92672>{</span>
  default <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>
  description <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;number of network interfaces which VM has&#34;</span>
<span style=color:#f92672>}</span>

variable private_network_bridge <span style=color:#f92672>{</span>
  type <span style=color:#f92672>=</span> string
  default <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;virbr0&#34;</span>
  description <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;existing network bridge on host that VM needs to connect to private network&#34;</span>
<span style=color:#f92672>}</span>

variable public_network_bridge <span style=color:#f92672>{</span>
  type <span style=color:#f92672>=</span> string
  default <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;virbr1&#34;</span>
  description <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;existing network bridge on host that VM needs to connect to public network&#34;</span>
<span style=color:#f92672>}</span>

<span style=color:#75715e>#variable user_data {</span>
<span style=color:#75715e>#  type = string</span>
<span style=color:#75715e>#}</span>

variable autostart <span style=color:#f92672>{</span>
  default <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;true&#34;</span>
  type <span style=color:#f92672>=</span> string
<span style=color:#f92672>}</span>

<span style=color:#75715e>################################################################################</span>
<span style=color:#75715e># PROVIDERS</span>
<span style=color:#75715e>################################################################################</span>

<span style=color:#75715e># instance the provider</span>
provider <span style=color:#e6db74>&#34;libvirt&#34;</span> <span style=color:#f92672>{</span>
  uri <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;qemu:///system&#34;</span>
<span style=color:#f92672>}</span>

<span style=color:#75715e># If you want to call remote libvirt provider.</span> 
<span style=color:#75715e>#provider &#34;libvirt&#34; {</span>
<span style=color:#75715e>#  uri = &#34;qemu+tcp://${var.libvirt_host}/system&#34;</span>
<span style=color:#75715e>#}</span>

<span style=color:#75715e>################################################################################</span>
<span style=color:#75715e># DATA TEMPLATES</span>
<span style=color:#75715e>################################################################################</span>

<span style=color:#75715e># https://www.terraform.io/docs/providers/template/d/file.html</span>

<span style=color:#75715e># https://www.terraform.io/docs/providers/template/d/cloudinit_config.html</span>
data <span style=color:#e6db74>&#34;template_file&#34;</span> <span style=color:#e6db74>&#34;user_data&#34;</span> <span style=color:#f92672>{</span>
  count <span style=color:#f92672>=</span> var.VM_COUNT
  template <span style=color:#f92672>=</span> file<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>path.module<span style=color:#e6db74>}</span><span style=color:#e6db74>/cloud_init.cfg</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>)</span>
  vars <span style=color:#f92672>=</span> <span style=color:#f92672>{</span>
    HOSTNAME <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>var.VM_HOSTNAME<span style=color:#e6db74>}</span><span style=color:#e6db74>-</span><span style=color:#e6db74>${</span>count.index + 1<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>
  <span style=color:#f92672>}</span>
<span style=color:#f92672>}</span>

<span style=color:#75715e>#data &#34;template_file&#34; &#34;network_config&#34; {</span>
<span style=color:#75715e>#  template = file(&#34;${path.module}/network_config.cfg&#34;)</span>
<span style=color:#75715e>#}</span>


<span style=color:#75715e>################################################################################</span>
<span style=color:#75715e># ANSIBLE ITEMS</span>
<span style=color:#75715e>################################################################################</span>
resource <span style=color:#e6db74>&#34;ansible_group&#34;</span> <span style=color:#e6db74>&#34;kube-deploy&#34;</span> <span style=color:#f92672>{</span>
  inventory_group_name <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;kube-deploy&#34;</span>
<span style=color:#f92672>}</span>

resource <span style=color:#e6db74>&#34;ansible_group&#34;</span> <span style=color:#e6db74>&#34;kube-master&#34;</span> <span style=color:#f92672>{</span>
  inventory_group_name <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;kube-master&#34;</span>
<span style=color:#f92672>}</span>

resource <span style=color:#e6db74>&#34;ansible_group&#34;</span> <span style=color:#e6db74>&#34;kube-node&#34;</span> <span style=color:#f92672>{</span>
  inventory_group_name <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;kube-node&#34;</span>
<span style=color:#f92672>}</span>

resource <span style=color:#e6db74>&#34;ansible_group&#34;</span> <span style=color:#e6db74>&#34;etcd&#34;</span> <span style=color:#f92672>{</span>
  inventory_group_name <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;etcd&#34;</span>
<span style=color:#f92672>}</span>

resource <span style=color:#e6db74>&#34;ansible_group&#34;</span> <span style=color:#e6db74>&#34;k8s-cluster&#34;</span> <span style=color:#f92672>{</span>
  inventory_group_name <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;k8s-cluster&#34;</span>
  children <span style=color:#f92672>=</span> <span style=color:#f92672>[</span><span style=color:#e6db74>&#34;kube-master&#34;</span>, <span style=color:#e6db74>&#34;kube-node&#34;</span><span style=color:#f92672>]</span>
<span style=color:#f92672>}</span>

<span style=color:#75715e># if count &gt; 3, then we have 3 ectds, 3 kube-master, count kube-nodes</span>

<span style=color:#75715e># The first node should be kube-deploy/kube-master/kube-node/etcd.</span> 
resource <span style=color:#e6db74>&#34;ansible_host&#34;</span> <span style=color:#e6db74>&#34;deploynode&#34;</span> <span style=color:#f92672>{</span>
    groups <span style=color:#f92672>=</span> <span style=color:#f92672>[</span><span style=color:#e6db74>&#34;kube-master&#34;</span>, <span style=color:#e6db74>&#34;etcd&#34;</span>, <span style=color:#e6db74>&#34;kube-node&#34;</span>, <span style=color:#e6db74>&#34;kube-deploy&#34;</span><span style=color:#f92672>]</span>
    inventory_hostname <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>var.VM_HOSTNAME<span style=color:#e6db74>}</span><span style=color:#e6db74>-1</span><span style=color:#e6db74>&#34;</span>
    vars <span style=color:#f92672>=</span> <span style=color:#f92672>{</span>
        ansible_user <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;root&#34;</span>
        ansible_ssh_private_key_file <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;./deploy.key&#34;</span>
        ansible_host <span style=color:#f92672>=</span> element<span style=color:#f92672>(</span>libvirt_domain.vm.*.network_interface.0.addresses.0, 0<span style=color:#f92672>)</span>
        ip <span style=color:#f92672>=</span> element<span style=color:#f92672>(</span>libvirt_domain.vm.*.network_interface.0.addresses.0, 0<span style=color:#f92672>)</span>
    <span style=color:#f92672>}</span>
    <span style=color:#75715e>#provisioner &#34;local-exec&#34; {</span>
    <span style=color:#75715e>#  command = &#34;sleep 40 &amp;&amp; ansible-playbook -i  /etc/ansible/terraform.py cluster.yml --extra-vars @rong-vars.yml&#34;</span>
    <span style=color:#75715e>#}</span>
<span style=color:#f92672>}</span>

<span style=color:#75715e># Create 2(kube-master, etcd, kube-node) nodes, node2, node3</span>
resource <span style=color:#e6db74>&#34;ansible_host&#34;</span> <span style=color:#e6db74>&#34;master&#34;</span> <span style=color:#f92672>{</span>
    count <span style=color:#f92672>=</span> var.VM_COUNT &gt;<span style=color:#f92672>=</span> <span style=color:#ae81ff>3</span> ? <span style=color:#ae81ff>2</span> : var.VM_COUNT -1
    groups <span style=color:#f92672>=</span> var.VM_COUNT &gt;<span style=color:#f92672>=</span> <span style=color:#ae81ff>3</span> ? <span style=color:#f92672>[</span><span style=color:#e6db74>&#34;kube-master&#34;</span>, <span style=color:#e6db74>&#34;etcd&#34;</span>, <span style=color:#e6db74>&#34;kube-node&#34;</span><span style=color:#f92672>]</span> : <span style=color:#f92672>[</span><span style=color:#e6db74>&#34;kube-master&#34;</span>, <span style=color:#e6db74>&#34;kube-node&#34;</span><span style=color:#f92672>]</span>
    <span style=color:#75715e>#inventory_hostname = format(&#34;%s-%d&#34;, &#34;node&#34;, count.index + 2)</span>
    inventory_hostname <span style=color:#f92672>=</span> format<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;%s-%d&#34;</span>, var.VM_HOSTNAME, count.index + 2<span style=color:#f92672>)</span>
    vars <span style=color:#f92672>=</span> <span style=color:#f92672>{</span>
        ansible_user <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;root&#34;</span>
        ansible_ssh_private_key_file <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;./deploy.key&#34;</span>
        ansible_host <span style=color:#f92672>=</span> element<span style=color:#f92672>(</span>libvirt_domain.vm.*.network_interface.0.addresses.0, count.index+1<span style=color:#f92672>)</span>
        ip <span style=color:#f92672>=</span> element<span style=color:#f92672>(</span>libvirt_domain.vm.*.network_interface.0.addresses.0, count.index+1<span style=color:#f92672>)</span>
    <span style=color:#f92672>}</span>
<span style=color:#f92672>}</span>

<span style=color:#75715e># others should be kube-nodes</span>
resource <span style=color:#e6db74>&#34;ansible_host&#34;</span> <span style=color:#e6db74>&#34;worker&#34;</span> <span style=color:#f92672>{</span>
    count <span style=color:#f92672>=</span> var.VM_COUNT &gt; <span style=color:#ae81ff>3</span> ? var.VM_COUNT - <span style=color:#ae81ff>3</span> : <span style=color:#ae81ff>0</span>
    groups <span style=color:#f92672>=</span> <span style=color:#f92672>[</span><span style=color:#e6db74>&#34;kube-node&#34;</span><span style=color:#f92672>]</span>
    <span style=color:#75715e>#inventory_hostname = &#34;node${count.index + 4}&#34;</span>
    <span style=color:#75715e>#inventory_hostname = format(&#34;%s-%d&#34;, &#34;node&#34;, count.index + 4)</span>
    inventory_hostname <span style=color:#f92672>=</span> format<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;%s-%d&#34;</span>, var.VM_HOSTNAME, count.index + 4<span style=color:#f92672>)</span>
    vars <span style=color:#f92672>=</span> <span style=color:#f92672>{</span>
        ansible_user <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;root&#34;</span>
        ansible_ssh_private_key_file <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;./deploy.key&#34;</span>
        ansible_host <span style=color:#f92672>=</span> element<span style=color:#f92672>(</span>libvirt_domain.vm.*.network_interface.0.addresses.0, count.index+3<span style=color:#f92672>)</span>
        ip <span style=color:#f92672>=</span> element<span style=color:#f92672>(</span>libvirt_domain.vm.*.network_interface.0.addresses.0, count.index+3<span style=color:#f92672>)</span>
    <span style=color:#f92672>}</span>
<span style=color:#f92672>}</span>

<span style=color:#75715e>################################################################################</span>
<span style=color:#75715e># RESOURCES</span>
<span style=color:#75715e>################################################################################</span>
resource <span style=color:#e6db74>&#34;libvirt_pool&#34;</span> <span style=color:#e6db74>&#34;vm&#34;</span> <span style=color:#f92672>{</span>
  name <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>var.VM_HOSTNAME<span style=color:#e6db74>}</span><span style=color:#e6db74>_pool</span><span style=color:#e6db74>&#34;</span>
  type <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;dir&#34;</span>
  path <span style=color:#f92672>=</span> abspath<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>var.LIBVIRT_POOL_DIR<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>)</span>
<span style=color:#f92672>}</span>

<span style=color:#75715e># We fetch the disk image for the operating system from the given url. For the base image.</span> 
resource <span style=color:#e6db74>&#34;libvirt_volume&#34;</span> <span style=color:#e6db74>&#34;vm_disk_image&#34;</span> <span style=color:#f92672>{</span>
  name   <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>var.VM_HOSTNAME<span style=color:#e6db74>}</span><span style=color:#e6db74>_disk_image.</span><span style=color:#e6db74>${</span>var.VM_IMG_FORMAT<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>
  <span style=color:#75715e># Or you could specify like `pool = &#34;transfer&#34;`</span>
  pool   <span style=color:#f92672>=</span> libvirt_pool.vm.name
  source <span style=color:#f92672>=</span> var.VM_IMG_URL
  format <span style=color:#f92672>=</span> var.VM_IMG_FORMAT
<span style=color:#f92672>}</span>

// It will use the disk image fetched at <span style=color:#e6db74>`</span>libirt_volume.vm_disk_image<span style=color:#e6db74>`</span> as the
//  base one to build the worker VM.
resource <span style=color:#e6db74>&#34;libvirt_volume&#34;</span> <span style=color:#e6db74>&#34;vm_worker&#34;</span> <span style=color:#f92672>{</span>
  count  <span style=color:#f92672>=</span> var.VM_COUNT
  name   <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;</span><span style=color:#e6db74>worker_</span><span style=color:#e6db74>${</span>var.VM_HOSTNAME<span style=color:#e6db74>}</span><span style=color:#e6db74>-</span><span style=color:#e6db74>${</span>count.index + 1<span style=color:#e6db74>}</span><span style=color:#e6db74>.</span><span style=color:#e6db74>${</span>var.VM_IMG_FORMAT<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>
  base_volume_id <span style=color:#f92672>=</span> libvirt_volume.vm_disk_image.id
  pool   <span style=color:#f92672>=</span> libvirt_volume.vm_disk_image.pool
<span style=color:#f92672>}</span>

<span style=color:#75715e>#*# Create a public network for the VMs</span>
<span style=color:#75715e>#*# https://www.ipaddressguide.com/cidrv</span>
<span style=color:#75715e>#*resource &#34;libvirt_network&#34; &#34;vm_public_network&#34; {</span>
<span style=color:#75715e>#*   name = &#34;${var.VM_HOSTNAME}_network&#34;</span>
<span style=color:#75715e>#*   autostart = true</span>
<span style=color:#75715e>#*   mode = &#34;nat&#34;</span>
<span style=color:#75715e>#*   domain = &#34;${var.VM_HOSTNAME}.local&#34;</span>
<span style=color:#75715e>#*</span>
<span style=color:#75715e>#*   # TODO: FIX CIDR ADDRESSES RANGE?</span>
<span style=color:#75715e>#*   # With `wait_for_lease` enabled, we get an error in the end of the VMs</span>
<span style=color:#75715e>#*   #  creation:</span>
<span style=color:#75715e>#*   #   - &#39;Requested operation is not valid: the address family of a host entry IP must match the address family of the dhcp element&#39;s parent&#39;</span>
<span style=color:#75715e>#*   # But the VMs will be running and accessible via ssh.</span>
<span style=color:#75715e>#*   addresses = [&#34;${var.VM_CIDR_RANGE}&#34;]</span>
<span style=color:#75715e>#*</span>
<span style=color:#75715e>#*   dhcp {</span>
<span style=color:#75715e>#*    enabled = true</span>
<span style=color:#75715e>#*   }</span>
<span style=color:#75715e>#*   dns {</span>
<span style=color:#75715e>#*    enabled = true</span>
<span style=color:#75715e>#*   }</span>
<span style=color:#75715e>#*}</span>

<span style=color:#75715e># for more info about paramater check this out</span> 
<span style=color:#75715e># https://github.com/dmacvicar/terraform-provider-libvirt/blob/master/website/docs/r/cloudinit.html.markdown</span>
<span style=color:#75715e># Use CloudInit to add our ssh-key to the instance</span>
<span style=color:#75715e># you can add also meta_data field</span>
resource <span style=color:#e6db74>&#34;libvirt_cloudinit_disk&#34;</span> <span style=color:#e6db74>&#34;cloudinit&#34;</span> <span style=color:#f92672>{</span>
  count <span style=color:#f92672>=</span> var.VM_COUNT
  name           <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>var.VM_HOSTNAME<span style=color:#e6db74>}</span><span style=color:#e6db74>-</span><span style=color:#e6db74>${</span>count.index + 1<span style=color:#e6db74>}</span><span style=color:#e6db74>_cloudinit.iso</span><span style=color:#e6db74>&#34;</span>
  <span style=color:#75715e>#user_data      = data.template_file.user_data.rendered</span> 
  user_data      <span style=color:#f92672>=</span> data.template_file.user_data<span style=color:#f92672>[</span>count.index<span style=color:#f92672>]</span>.rendered
  pool           <span style=color:#f92672>=</span> libvirt_pool.vm.name
<span style=color:#f92672>}</span>



resource <span style=color:#e6db74>&#34;libvirt_domain&#34;</span> <span style=color:#e6db74>&#34;vm&#34;</span> <span style=color:#f92672>{</span>
  count  <span style=color:#f92672>=</span> var.VM_COUNT
  name   <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>var.VM_HOSTNAME<span style=color:#e6db74>}</span><span style=color:#e6db74>-</span><span style=color:#e6db74>${</span>count.index + 1<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>
  <span style=color:#75715e>#memory      = &#34;${var.memory_size}&#34;</span>
  memory      <span style=color:#f92672>=</span> var.memory_size
  <span style=color:#75715e>#vcpu        = &#34;${var.num_cpu}&#34;</span>
  vcpu        <span style=color:#f92672>=</span> var.num_cpu
  <span style=color:#75715e>#autostart   = &#34;${var.autostart}&#34;</span>
  autostart   <span style=color:#f92672>=</span> var.autostart

  <span style=color:#75715e># TODO: FIX qemu-ga?</span>
  <span style=color:#75715e># qemu-ga needs to be installed and working inside the VM, and currently is</span>
  <span style=color:#75715e>#  not working. Maybe it needs some configuration.</span>
  qemu_agent <span style=color:#f92672>=</span> true
  <span style=color:#75715e>#cloudinit = &#34;${libvirt_cloudinit_disk.cloudinit.id}&#34;</span>
  cloudinit <span style=color:#f92672>=</span> element<span style=color:#f92672>(</span>libvirt_cloudinit_disk.cloudinit.*.id, count.index<span style=color:#f92672>)</span>


  <span style=color:#75715e># attach network interface to default network(192.168.122.0/24)</span>
  <span style=color:#75715e># Or we could specify a new networking created in resource and attached to it.</span> 
  network_interface <span style=color:#f92672>{</span>
    network_name   <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;default&#34;</span>
    hostname   <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>var.VM_HOSTNAME<span style=color:#e6db74>}</span><span style=color:#e6db74>-</span><span style=color:#e6db74>${</span>count.index + 1<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>
    wait_for_lease <span style=color:#f92672>=</span> true
  <span style=color:#f92672>}</span>

  <span style=color:#75715e>#* Attached to our created network.</span>
  <span style=color:#75715e>#*network_interface {</span>
  <span style=color:#75715e>#*  #hostname = &#34;${var.VM_HOSTNAME}-${count.index + 1}&#34;</span>
  <span style=color:#75715e>#*  network_id = &#34;${libvirt_network.vm_public_network.id}&#34;</span>
  <span style=color:#75715e>#*  #network_name = &#34;${libvirt_network.vm_public_network.name}&#34;</span>

  <span style=color:#75715e>#*  #addresses = [&#34;${cidrhost(libvirt_network.vm_public_network.addresses, count.index + 1)}&#34;]</span>
  <span style=color:#75715e>#*  addresses = [&#34;${cidrhost(var.VM_CIDR_RANGE, count.index + 1)}&#34;]</span>

  <span style=color:#75715e>#*  # TODO: Fix wait for lease?</span>
  <span style=color:#75715e>#*  # qemu-ga must be running inside the VM. See notes above in `qemu_agent`.</span>
  <span style=color:#75715e>#*  wait_for_lease = true</span>
  <span style=color:#75715e>#*}</span>

  graphics <span style=color:#f92672>{</span>
    type <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;vnc&#34;</span>
    listen_type <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;address&#34;</span>
    autoport <span style=color:#f92672>=</span> true
  <span style=color:#f92672>}</span>

  <span style=color:#75715e># IMPORTANT</span>
  <span style=color:#75715e># Ubuntu can hang is a isa-serial is not present at boot time.</span>
  <span style=color:#75715e># If you find your CPU 100% and never is available this is why.</span>
  #
  <span style=color:#75715e># This is a known bug on cloud images, since they expect a console</span>
  <span style=color:#75715e># we need to pass it:</span>
  <span style=color:#75715e># https://bugs.launchpad.net/cloud-images/+bug/1573095</span>
  console <span style=color:#f92672>{</span>
    type        <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;pty&#34;</span>
    target_port <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;0&#34;</span>
    target_type <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;serial&#34;</span>
  <span style=color:#f92672>}</span>

  console <span style=color:#f92672>{</span>
    type        <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;pty&#34;</span>
    target_type <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;virtio&#34;</span>
    target_port <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;1&#34;</span>
  <span style=color:#f92672>}</span>

  disk <span style=color:#f92672>{</span>
    volume_id <span style=color:#f92672>=</span> element<span style=color:#f92672>(</span>libvirt_volume.vm_worker.*.id, count.index<span style=color:#f92672>)</span>
  <span style=color:#f92672>}</span>

<span style=color:#f92672>}</span>
<span style=color:#75715e>################################################################################</span>
<span style=color:#75715e># TERRAFORM CONFIG</span>
<span style=color:#75715e>################################################################################</span>

terraform <span style=color:#f92672>{</span>
  required_version <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;&gt;= 0.12&#34;</span>
<span style=color:#f92672>}</span>

<span style=color:#75715e>################################################################################</span>
<span style=color:#75715e># TERRAFORM OUTPUT</span>
<span style=color:#75715e>################################################################################</span>
#
output <span style=color:#e6db74>&#34;ip&#34;</span> <span style=color:#f92672>{</span>
  value <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>libvirt_domain.vm.*.network_interface.0.addresses.0<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>
<span style=color:#f92672>}</span>
</code></pre></div><p>local exec command , added to:</p><pre><code>    provisioner &quot;local-exec&quot; {
      command = &quot;sleep 40 &amp;&amp; ansible-playbook -i  /etc/ansible/terraform.py cluster.yml --extra-vars @rong-vars.yml&quot;
    }

</code></pre><p>逐行解释如下:</p></div><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/blog/2019/12/06/buildingterraform-provider-libvirt/>Buildingterraform-provider-libvirt</a></h1><span class=post-date>Dec 6, 2019<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><p>Build terraform-provider-libvirt for debian9.0.</p><p>Steps:</p><p>Get system info:</p><pre><code>root@debian:~# cat /etc/issue
Debian GNU/Linux 9 \n \l

root@debian:~# cat /etc/debian_version 
9.0

</code></pre><p>wget the terraform and mv it to /usr/bin, then start building the plugin:</p><pre><code># vim /etc/apt/sources.list
deb http://mirrors.163.com/debian/ stretch main non-free contrib
deb http://mirrors.163.com/debian/ stretch-updates main non-free contrib
deb http://mirrors.163.com/debian/ stretch-backports main non-free contrib
deb http://mirrors.163.com/debian-security/ stretch/updates main non-free contrib
# apt-get update -y
# apt-get install libvirt-dev git build-essential golang=2:1.11~1~bpo9+1 golang=2:1.11~1~bpo9+1 golang-doc=2:1.11~1~bpo9+1 golang-go=2:1.11~1~bpo9+1 golang-src=2:1.11~1~bpo9+1
# mkdir /root/go
# vim /root/.bashrc
export GOPATH=/root/go
export PATH=$PATH:$GOPATH/bin
# export CGO_ENABLED=&quot;1&quot;
# mkdir -p $GOPATH/src/github.com/dmacvicar; cd $GOPATH/src/github.com/dmacvicar
# git clone https://github.com/dmacvicar/terraform-provider-libvirt.git
# cd $GOPATH/src/github.com/dmacvicar/terraform-provider-libvirt
# make install
</code></pre><p>After building, go to <code>/root/go/bin</code> and examine the built plugin:</p><pre><code>root@debian:~/go/bin# ./terraform-provider-libvirt --version
./terraform-provider-libvirt e9ff32f1ec5825dcf05481cb7ef6a3b645696a4f-dirty
Compiled against library: libvirt 3.0.0
Using library: libvirt 3.0.0
</code></pre><p>Now you got plugin compiled and ready to use on debian 9.0</p></div><ul class=pagination><li class=page-item><a href=/ class=page-link aria-label=First><span aria-hidden=true>&#171;&#171;</span></a></li><li class=page-item><a href=/page/51/ class=page-link aria-label=Previous><span aria-hidden=true>&#171;</span></a></li><li class=page-item><a class=page-link href=/>1</a></li><li class=page-item><a class=page-link href=/page/2/>2</a></li><li class=page-item><a class=page-link href=/page/3/>3</a></li><li class="page-item disabled"><span aria-hidden=true>&nbsp;&mldr;&nbsp;</span></li><li class=page-item><a class=page-link href=/page/51/>51</a></li><li class="page-item active"><a class=page-link href=/page/52/>52</a></li><li class=page-item><a class=page-link href=/page/53/>53</a></li><li class="page-item disabled"><span aria-hidden=true>&nbsp;&mldr;&nbsp;</span></li><li class=page-item><a class=page-link href=/page/238/>238</a></li><li class=page-item><a href=/page/53/ class=page-link aria-label=Next><span aria-hidden=true>&#187;</span></a></li><li class=page-item><a href=/page/238/ class=page-link aria-label=Last><span aria-hidden=true>&#187;&#187;</span></a></li></ul></div></div><script src=http://purplepalmdash.github.io/js/highlight.pack.js></script><script>hljs.initHighlightingOnLoad();</script></body></html>