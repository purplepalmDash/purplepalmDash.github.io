<!doctype html><html xmlns=http://www.w3.org/1999/xhtml xml:lang=en lang=en-us><head><meta name=generator content="Hugo 0.64.0"><link href=http://gmpg.org/xfn/11 rel=profile><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><title>Dash &#183; Dash</title><link rel=stylesheet href=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap-theme.min.css><link rel=stylesheet href="https://purplepalmdash.github.io/css/poole.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/hyde.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/poole-overrides.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/hyde-overrides.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/hyde-a.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/custom-additions.css?ref=abc124"><link rel=stylesheet href=https://purplepalmdash.github.io/css/highlight/googlecode.css><link rel=stylesheet href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.3.0/css/font-awesome.min.css><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.5/styles/docco.min.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/1.10.2/jquery.min.js></script><script type=text/javascript src=/js/html2canvas.js></script><script type=text/javascript>function genPostShot(){var rightNow=new Date();var imageName=rightNow.toISOString().slice(0,16).replace(/(-)|(:)|(T)/g,"");imageName+='.jpg'
html2canvas(document.getElementsByClassName('post'),{background:'#FFFFFF',onrendered:function(canvas){$('#test').attr('href',canvas.toDataURL("image/jpeg"));$('#test').attr('download',imageName);$('#test')[0].click();}});};</script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.5/highlight.min.js></script><script>hljs.initHighlightingOnLoad();</script><link rel=apple-touch-icon-precomposed sizes=144x144 href="http://purplepalmdash.github.io/touch-icon-144-precomposed.png?ref=abc124"><link href="http://purplepalmdash.github.io/favicon.png?ref=abc124" rel=icon><link href=%7balternate%20%7bRSS%20application/rss+xml%20%20index%20alternate%20%20false%20false%20true%20false%20false%200%7d%20/index.xml%20http://purplepalmdash.github.io/index.xml%7d rel=alternate type=application/rss+xml title="Dash &#183; Dash"><meta name=description content><meta name=keywords content="unix,virtualization,embedded,linux"></head><body class=theme-base-0c><div class=sidebar><div class="container sidebar-sticky"><div class=sidebar-about><img src=http://purplepalmdash.github.io/images/mylogo.jpeg alt=gravatar><h1><a href=http://purplepalmdash.github.io/>很惭愧，就做了一点微小的工作</a></h1><a href=http://purplepalmdash.github.io/><p>Dash</p></a></div><ul class=sidebar-nav><li class=sidebar-nav-item><a href=http://purplepalmdash.github.io/post/>All Posts</a></li><li class=sidebar-nav-item><a href=http://purplepalmdash.github.io/categories/technology/>Technology</a></li><li class=sidebar-nav-item><a href=http://purplepalmdash.github.io/categories/life/>Life</a></li><li class=sidebar-nav-item><a href=http://purplepalmdash.github.io/categories/linuxtips/>LinuxTips</a></li></ul><ul class=sidebar-nav><li class=sidebar-nav-item><a href=https://github.com/purplepalmdash><i class="fa fa-github-square fa-3x"></i></a><a href=https://cn.linkedin.com/in/yang-feipeng-1b909319><i class="fa fa-linkedin-square fa-3x"></i></a><a href=https://plus.google.com/u/0/106572959364703833986><i class="fa fa-google-plus-square fa-3x"></i></a><a href=https://www.facebook.com/yang.feipeng><i class="fa fa-facebook-square fa-3x"></i></a><a href=https://twitter.com/dashwillfly><i class="fa fa-twitter-square fa-3x"></i></a></li></ul></div></div><div class="content container"><div class=posts><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/blog/2021/04/11/workingtipsonshrinkingccse/>WorkingTipsOnShrinkingCCSE</a></h1><span class=post-date>Apr 11, 2021<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><h3 id=repository-shrinking>Repository Shrinking</h3><p>Create a new vm via following command:</p><pre><code># cd /var/lib/libvirt/qemu/save
### Following is for creating a new vm for saving rpms
# virsh dumpxml node1&gt;example.xml
# vim example.xml 
# qemu-img create -f qcow2 -b ccsebaseimage.qcow2 saverpms.qcow2 
Formatting 'saverpms.qcow2', fmt=qcow2 size=536870912000 backing_file=ccsebaseimage.qcow2 cluster_size=65536 lazy_refcounts=off refcount_bits=16
# virsh define example.xml 
Domain nodetmp defined from example.xml
# virsh start nodetmp
Domain nodetmp started
# virsh net-dhcp-leases default
### Getting the ip address for nodetmp(10.17.18.199)
# scp ./ccse-offline-files.tar.gz root@10.17.18.199:/home/
# ssh root@10.17.18.199
</code></pre><p>Following is on <code>10.17.18.199</code>:</p><pre><code>[root@first ~]# cd /home/
[root@first home]# tar xzvf ccse-offline-files.tar.gz
# vi /etc/yum.conf
keepcache=1
### Add a new vm disk (vdb)
# fdisk /dev/vdb
# mkfs.ext4 /dev/vdb1
# mkdir /dcos
# mount /dev/vdb1 /dcos
# vi /etc/fstab 
/dev/vdb1 /dcos                   ext4     defaults        0 0
# mount -a
# exit
</code></pre><p>Bug-fix(lsof):</p><pre><code># scp ./Packages/lsof-4.87-6.el7.x86_64.rpm root@10.17.18.199:/root/
</code></pre><p>Backup the vm disks on host machine:</p><pre><code># virsh destroy nodetmp
# mv saverpms.qcow2 saverpms1.qcow2
# qemu-img create -f qcow2 -b saverpms1.qcow2 saverpms.qcow2
# virsh start nodetmp
# ssh root@10.17.18.199
</code></pre><p>Re-login, and run:</p><pre><code>#  rpm -ivh /root/lsof-4.87-6.el7.x86_64.rpm 
# cd /home/ccse-xxxxxxxx
# vi config/config.yaml
common:
  # 控制台和/或Harbor所在的主机IP
  host: 10.17.18.199
# vim ./files/offline-repo/ccse-centos7-base.repo
	#[ccse-centos7-base]
	#name=ccse-offline-repo
	#baseurl=file://{centos7_base_repo_dir}
	#enabled=1
	#gpgcheck=0
	[ccse-centos7-base]
	name=Centos local yum repo for k8s
	baseurl=http://10.17.18.2:8200/repo/x86_64/centos7-base
	gpgcheck=0
	enabled=1
	proxy=_none_
# ./deploy.sh install all 2&gt;&amp;1 | sudo tee install-log_`date &quot;+%Y%m%d%H%M&quot;`
</code></pre><p>Notice, <code>10.17.18.2</code> is for existing ccse console.<br>After deployment, the cached rpms is listed as:</p><pre><code># find /var/cache | grep rpm$
/var/cache/yum/x86_64/7/ccse-centos7-base/packages/audit-2.8.5-4.el7.x86_64.rpm
/var/cache/yum/x86_64/7/ccse-centos7-base/packages/audit-libs-2.8.5-4.el7.x86_64.rpm
/var/cache/yum/x86_64/7/ccse-centos7-base/packages/audit-libs-python-2.8.5-4.el7.x86_64.rpm
/var/cache/yum/x86_64/7/ccse-centos7-base/packages/checkpolicy-2.5-8.el7.x86_64.rpm
/var/cache/yum/x86_64/7/ccse-centos7-base/packages/libsemanage-python-2.5-14.el7.x86_64.rpm
/var/cache/yum/x86_64/7/ccse-centos7-base/packages/policycoreutils-2.5-34.el7.x86_64.rpm
/var/cache/yum/x86_64/7/ccse-centos7-base/packages/policycoreutils-python-2.5-34.el7.x86_64.rpm
/var/cache/yum/x86_64/7/ccse-centos7-base/packages/python-IPy-0.75-6.el7.noarch.rpm
/var/cache/yum/x86_64/7/ccse-centos7-base/packages/setools-libs-3.3.8-4.el7.x86_64.rpm
/var/cache/yum/x86_64/7/ccse-centos7-base/packages/libcgroup-0.41-21.el7.x86_64.rpm
/var/cache/yum/x86_64/7/ccse-centos7-base/packages/unzip-6.0-21.el7.x86_64.rpm
</code></pre><p>Now enable the visit for ccse console(web ui):</p><pre><code># systemctl stop firewalld
# systemctl disable firewalld
# setenforce 0
# vi /etc/selinux/config 
SELINUX=disabled
</code></pre><p>ccse webui:</p><p><img src=/images/2021_04_12_10_37_55_515x298.jpg alt=/images/2021_04_12_10_37_55_515x298.jpg></p><p>Create a new vm and added it on ccse webui, in newly added vm do following command:</p><pre><code># vi /etc/yum.conf 
keepcached
# systemctl stop firewalld
# systemctl disable firewalld
# setenforce 0
# vi /etc/selinux/config 
SELINUX=disabled
</code></pre><p>Create a new cluster, and fetch the new vm&rsquo;s rpm cache:</p><pre><code>[root@first cache]# find . | grep rpm$
./yum/x86_64/7/ccse-centos7-base/packages/audit-2.8.5-4.el7.x86_64.rpm
./yum/x86_64/7/ccse-centos7-base/packages/audit-libs-2.8.5-4.el7.x86_64.rpm
./yum/x86_64/7/ccse-centos7-base/packages/checkpolicy-2.5-8.el7.x86_64.rpm
./yum/x86_64/7/ccse-centos7-base/packages/audit-libs-python-2.8.5-4.el7.x86_64.rpm
./yum/x86_64/7/ccse-centos7-base/packages/libsemanage-python-2.5-14.el7.x86_64.rpm
./yum/x86_64/7/ccse-centos7-base/packages/libcgroup-0.41-21.el7.x86_64.rpm
./yum/x86_64/7/ccse-centos7-base/packages/policycoreutils-2.5-34.el7.x86_64.rpm
./yum/x86_64/7/ccse-centos7-base/packages/python-IPy-0.75-6.el7.noarch.rpm
./yum/x86_64/7/ccse-centos7-base/packages/setools-libs-3.3.8-4.el7.x86_64.rpm
./yum/x86_64/7/ccse-centos7-base/packages/policycoreutils-python-2.5-34.el7.x86_64.rpm
./yum/x86_64/7/ccse-centos7-base/packages/conntrack-tools-1.4.4-7.el7.x86_64.rpm
./yum/x86_64/7/ccse-centos7-base/packages/libnetfilter_cttimeout-1.0.0-7.el7.x86_64.rpm
./yum/x86_64/7/ccse-centos7-base/packages/libnetfilter_queue-1.0.2-2.el7_2.x86_64.rpm
./yum/x86_64/7/ccse-centos7-base/packages/socat-1.7.3.2-2.el7.x86_64.rpm
./yum/x86_64/7/ccse-centos7-base/packages/libnetfilter_cthelper-1.0.0-11.el7.x86_64.rpm
./yum/x86_64/7/ccse-k8s/packages/container-selinux-2.119.1-1.c57a6f9.el7.noarch.rpm
./yum/x86_64/7/ccse-k8s/packages/docker-ce-18.09.9-3.el7.x86_64.rpm
./yum/x86_64/7/ccse-k8s/packages/containerd.io-1.2.13-3.2.el7.x86_64.rpm
./yum/x86_64/7/ccse-k8s/packages/docker-ce-cli-18.09.9-3.el7.x86_64.rpm
./yum/x86_64/7/ccse-k8s/packages/3f1db71d0bb6d72bc956d788ffee737714e5717c629b26355a2dcf1dba4ad231-kubelet-1.17.3-0.x86_64.rpm
./yum/x86_64/7/ccse-k8s/packages/548a0dcd865c16a50980420ddfa5fbccb8b59621179798e6dc905c9bf8af3b34-kubernetes-cni-0.7.5-0.x86_64.rpm
./yum/x86_64/7/ccse-k8s/packages/35625b6ab1da6c58ce4946742181c0dcf9ac9b6c2b5bea2c13eed4876024c342-kubectl-1.17.3-0.x86_64.rpm
</code></pre><h3 id=harbor-shrinking>harbor shrinking</h3><p>Save the harbor images:</p><pre><code>[root@first ~]# docker save -o harbor.tar goharbor/chartmuseum-photon:v0.9.0-v1.8.6 goharbor/harbor-migrator:v1.8.6 goharbor/redis-photon:v1.8.6 goharbor/clair-photon:v2.1.0-v1.8.6 goharbor/notary-server-photon:v0.6.1-v1.8.6 goharbor/notary-signer-photon:v0.6.1-v1.8.6 goharbor/harbor-registryctl:v1.8.6 goharbor/registry-photon:v2.7.1-patch-2819-v1.8.6 goharbor/nginx-photon:v1.8.6 goharbor/harbor-log:v1.8.6 goharbor/harbor-jobservice:v1.8.6 goharbor/harbor-core:v1.8.6 goharbor/harbor-portal:v1.8.6 goharbor/harbor-db:v1.8.6 goharbor/prepare:v1.8.6
[root@first ~]# ls -l -h harbor.tar 
-rw-------. 1 root root 1.5G Apr 11 23:31 harbor.tar
[root@first ~]# cp harbor.tar harbor.tar.back
[root@first ~]# xz -T4 harbor.tar
[root@first ~]# ls -l -h harbor.tar.*
-rw-------. 1 root root 1.5G Apr 11 23:31 harbor.tar.back
-rw-------. 1 root root 428M Apr 11 23:31 harbor.tar.xz
</code></pre><h3 id=rpm>rpm</h3><p>rpms combine:</p><pre><code>[root@first rpms]# ls -l -h | wc -l
12
##### After transferring from working node
#########################################
[root@first rpms]# cp /tmp/rpms/* .
cp: overwrite ‘./audit-2.8.5-4.el7.x86_64.rpm’? y
cp: overwrite ‘./audit-libs-2.8.5-4.el7.x86_64.rpm’? y
cp: overwrite ‘./audit-libs-python-2.8.5-4.el7.x86_64.rpm’? y
cp: overwrite ‘./checkpolicy-2.5-8.el7.x86_64.rpm’? y
cp: overwrite ‘./libcgroup-0.41-21.el7.x86_64.rpm’? y
cp: overwrite ‘./libsemanage-python-2.5-14.el7.x86_64.rpm’? y
cp: overwrite ‘./policycoreutils-2.5-34.el7.x86_64.rpm’? y
cp: overwrite ‘./policycoreutils-python-2.5-34.el7.x86_64.rpm’? y
cp: overwrite ‘./python-IPy-0.75-6.el7.noarch.rpm’? y
cp: overwrite ‘./setools-libs-3.3.8-4.el7.x86_64.rpm’? y
[root@first rpms]# ls -l -h | wc -l
17
</code></pre></div><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/blog/2021/03/18/workingtipsonkata/>WorkingTipsOnKata</a></h1><span class=post-date>Mar 18, 2021<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><h3 id=install--configuration>Install & Configuration</h3><p>Install kata on archlinux, first install snapd:</p><pre><code>$ yaourt snapd
$ sudo systemctl enable --now snapd.socket
</code></pre><p>Using snapd for installing kata:</p><pre><code>$ sudo snap install kata-containers --classic
</code></pre><p>Check the kata-container runtimes:</p><pre><code>$ kata-containers.runtime --version
kata-runtime  : 1.12.1
   commit   : b967088a667018b7468a9f93d48cb81650e0dfa4
   OCI specs: 1.0.1-dev
$ which kata-containers.runtime
/var/lib/snapd/snap/bin/kata-containers.runtime
</code></pre><p>Add the kata container runtime for docker-ce:</p><pre><code>$ sudo mkdir -p /etc/systemd/system/docker.service.d
$ sudo vim /etc/systemd/system/docker.service.d/kata-containers.conf 
[Service]
ExecStart=
ExecStart=/usr/bin/dockerd -D --add-runtime kata-runtime=/snap/kata-containers/current/usr/bin/kata-runtime
$ sudo systemctl daemon-reload
$ sudo systemctl restart docker
</code></pre><p>Check the docker info:</p><pre><code>$ docker info | grep Runtime
 Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux kata-runtime runc
 Default Runtime: runc
</code></pre><h3 id=testing>Testing</h3><p>Run a busybox using kata-runtime:</p><pre><code>$ sudo docker run -ti --runtime kata-runtime busybox sh
</code></pre><p>Checking the docker hardware(qemu):</p><pre><code>/ # free -m
              total        used        free      shared  buff/cache   available
Mem:           1993          26        1965           0           2        1948
Swap:             0           0           0
/ # uname -a
Linux 172144f42ad4 5.4.60.container #1 SMP Wed Jan 20 17:43:09 UTC 2021 x86_64 GNU/Linux
</code></pre><p>Comparing to runc busybox:</p><pre><code>$ sudo docker run -it busybox /bin/sh
/ # free -m
              total        used        free      shared  buff/cache   available
Mem:          23932        3759       12883        1003        7289       18795
Swap:          2047           0        2047
/ # uname -a
Linux 7d484813ddd3 5.10.16-arch1-1 #1 SMP PREEMPT Sat, 13 Feb 2021 20:50:18 +0000 x86_64 GNU/Linux
</code></pre><p>Get the running qemu :</p><pre><code># ps -ef | grep qemu
root      130733  130681  0 14:41 ?        00:00:03 /var/lib/snapd/snap/kata-containers/716/usr/bin/qemu-system-x86_64 -name sandbox-172144f42ad4130671d2f3282f84be7d33f17ec9f308234d9172162f6dac8a1f -uuid 07ebc86a-91a7-4180-accd-c9d1dbd3ac29 -machine pc,accel=kvm,kernel_irqchip,nvdimm -cpu host,pmu=off -qmp unix:/
.....
</code></pre><h3 id=useful-tips>Useful tips</h3><p>Get the kata env:</p><pre><code>$ kata-containers.runtime kata-env
</code></pre><p>See if the system is ready for running kata:</p><pre><code>$ sudo kata-containers.runtime kata-check
</code></pre></div><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/blog/2021/03/12/workingtipsonrpixc/>WorkingTipsOnRPIXC</a></h1><span class=post-date>Mar 12, 2021<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><h3 id=目标>目标</h3><p>基于树莓派的arm64快速验证平台。</p><h3 id=系统准备>系统准备</h3><p>Ubuntu官网下载到<code>Ubuntu 20.04.2 LTS</code> 64位镜像:</p><p><a href=https://ubuntu.com/download/raspberry-pi>https://ubuntu.com/download/raspberry-pi</a></p><p><img src=/images/2021_03_12_09_45_02_1212x332.jpg alt=/images/2021_03_12_09_45_02_1212x332.jpg></p><p>插入tf卡，烧写img文件至tf卡中, Linux 命令为:</p><pre><code> $ sudo dd if=./ubuntu-20.04.2-preinstalled-server-arm64+raspi.img of=/dev/sdd bs=1M &amp;&amp; sudo sync
记录了3108+1 的读入
记录了3108+1 的写出
3259499520字节（3.3 GB，3.0 GiB）已复制，79.1856 s，41.2 MB/s
</code></pre><p>Windows下可自行下载rpi镜像烧写软件以完成烧写操作。</p><h3 id=初次登陆>初次登陆</h3><p>如果具备mini-hdmi转接线及鼠标，则可外接显示器用于登陆RPI。<br>如果不具备显示器，则可以通过接入网络来远程登陆RPI，登陆到局域网段的路由器上查看rpi获取到的Ip地址即可。</p><p>例如， 在路由器上获取到RPI IP地址:</p><pre><code>$ cat /var/lib/misc/dnsmasq.leases
1615556943 dc:a6:32:e2:0b:44 10.137.149.171 ubuntu ff:dc:6b:56:57:00:02:00:00:ab:11:b2:87:a0:99:d0:fb:b1:ce
</code></pre><p>而后用ssh登陆, 默认用户名/密码为ubuntu/ubuntu，初次登陆后会强制要求更改:</p><pre><code>$ ssh ubuntu@10.137.149.171
。。。。

WARNING: Your password has expired.
You must change your password now and login again!
Changing password for ubuntu.
Current password: 
New password: 
Retype new password: 
passwd: password updated successfully
Connection to 10.137.149.171 closed.
$ ssh ubuntu@10.137.149.171
ubuntu@10.137.149.171's password: 
Welcome to Ubuntu 20.04.2 LTS (GNU/Linux 5.4.0-1028-raspi aarch64)
</code></pre><h3 id=虚拟机开发环境准备>虚拟机开发环境准备</h3><p>安装基本桌面, 选择lightdm:</p><pre><code>$ sudo apt-get install lxde virt-manager tightvncserver net-tools
</code></pre><p><img src=/images/2021_03_12_10_12_41_512x417.jpg alt=/images/2021_03_12_10_12_41_512x417.jpg></p><p>开启vnc:</p><pre><code>$ vncserver
You will require a password to access your desktops.

Password: 
Verify:   
Would you like to enter a view-only password (y/n)? y
Password: 
Verify:   

New 'X' desktop is ubuntu:1

Creating default startup script /home/ubuntu/.vnc/xstartup
Starting applications specified in /home/ubuntu/.vnc/xstartup
Log file is /home/ubuntu/.vnc/ubuntu:1.log
</code></pre><p>此时需要先关闭正在运行的vncserver, 配置默认桌面环境后再重新创建:</p><pre><code>ubuntu@ubuntu:~$ vncserver -kill :1
Killing Xtightvnc process ID 30773
ubuntu@ubuntu:~$ vim ~/.vnc/xstartup 
#!/bin/sh
exec startlxde

ubuntu@ubuntu:~$ vncserver

New 'X' desktop is ubuntu:1

Starting applications specified in /home/ubuntu/.vnc/xstartup
Log file is /home/ubuntu/.vnc/ubuntu:1.log

</code></pre><p>此时可以使用vncviewer登陆:</p><p><img src=/images/2021_03_12_10_29_49_737x234.jpg alt=/images/2021_03_12_10_29_49_737x234.jpg></p><p>开启libvirtd权限:</p><pre><code>$ sudo systemctl enable libvirtd
$ sudo systemctl start libvirtd
$  sudo usermod -a -G kvm,libvirt  ubuntu
</code></pre><p>此时需重启rpi后，重新登陆/开启vnc后，验证virt-manager的可用性:</p><p><img src=/images/2021_03_12_10_38_23_792x442.jpg alt=/images/2021_03_12_10_38_23_792x442.jpg></p><h3 id=虚拟机系统安装>虚拟机系统安装</h3><p><img src=/images/2021_03_12_10_46_47_632x356.jpg alt=/images/2021_03_12_10_46_47_632x356.jpg></p><p><img src=/images/2021_03_12_10_47_23_497x497.jpg alt=/images/2021_03_12_10_47_23_497x497.jpg></p><p><img src=/images/2021_03_12_10_47_34_386x250.jpg alt=/images/2021_03_12_10_47_34_386x250.jpg></p><p><img src=/images/2021_03_12_10_47_50_428x281.jpg alt=/images/2021_03_12_10_47_50_428x281.jpg></p><p><img src=/images/2021_03_12_10_48_06_531x525.jpg alt=/images/2021_03_12_10_48_06_531x525.jpg></p><p>进入到安装界面后(All-In-One安装)：</p><p><img src=/images/2021_03_12_10_48_56_657x395.jpg alt=/images/2021_03_12_10_48_56_657x395.jpg></p><p>安装过程:</p><p><img src=/images/2021_03_12_10_54_08_682x525.jpg alt=/images/2021_03_12_10_54_08_682x525.jpg></p><p>安装完毕后可以备份一下初始化镜像以便后续使用:</p><pre><code>$ sudo virsh dumpxml ubuntu20.04 | grep qcow2
      &lt;driver name='qemu' type='qcow2'/&gt;
      &lt;source file='/var/lib/libvirt/images/ubuntu20.04.qcow2'/&gt;
ubuntu@ubuntu:~$ sudo cp /var/lib/libvirt/images/ubuntu20.04.qcow2 .

</code></pre><p>后续开始部署RONG:</p><p><img src=/images/2021_03_12_11_57_01_966x589.jpg alt=/images/2021_03_12_11_57_01_966x589.jpg></p><p>部署完毕后资源占用情况:</p><pre><code>root@node:/home/test/Rong# free -m
              total        used        free      shared  buff/cache   available
Mem:           5909        1790         132           2        3987        4205
Swap:             0           0           0
root@node:/home/test/Rong# df -h
Filesystem               Size  Used Avail Use% Mounted on
udev                     2.9G     0  2.9G   0% /dev
tmpfs                    591M  2.5M  589M   1% /run
/dev/mapper/vgnode-root   24G   13G   12G  52% /
</code></pre><h3 id=xc适配>XC适配</h3><p>选择国产操作系统ISO用于安装：</p><p><img src=/images/2021_03_12_12_09_23_546x515.jpg alt=/images/2021_03_12_12_09_23_546x515.jpg></p><p><img src=/images/2021_03_12_12_10_04_505x320.jpg alt=/images/2021_03_12_12_10_04_505x320.jpg></p><p><img src=/images/2021_03_12_12_10_19_501x256.jpg alt=/images/2021_03_12_12_10_19_501x256.jpg></p><p><img src=/images/2021_03_12_12_10_37_507x382.jpg alt=/images/2021_03_12_12_10_37_507x382.jpg></p><p>安装界面：</p><p><img src=/images/2021_03_12_12_11_29_648x177.jpg alt=/images/2021_03_12_12_11_29_648x177.jpg></p><p><img src=/images/2021_03_12_12_13_08_754x293.jpg alt=/images/2021_03_12_12_13_08_754x293.jpg></p><p><img src=/images/2021_03_12_12_13_25_669x176.jpg alt=/images/2021_03_12_12_13_25_669x176.jpg></p><p><img src=/images/2021_03_12_12_16_03_704x343.jpg alt=/images/2021_03_12_12_16_03_704x343.jpg></p><p><img src=/images/2021_03_12_12_16_21_676x294.jpg alt=/images/2021_03_12_12_16_21_676x294.jpg></p><p><img src=/images/2021_03_12_12_16_36_678x192.jpg alt=/images/2021_03_12_12_16_36_678x192.jpg></p><p><img src=/images/2021_03_12_12_16_49_686x245.jpg alt=/images/2021_03_12_12_16_49_686x245.jpg></p><p><img src=/images/2021_03_12_12_17_00_672x242.jpg alt=/images/2021_03_12_12_17_00_672x242.jpg></p><p><img src=/images/2021_03_12_12_17_19_692x218.jpg alt=/images/2021_03_12_12_17_19_692x218.jpg></p><p><img src=/images/2021_03_12_12_17_39_684x297.jpg alt=/images/2021_03_12_12_17_39_684x297.jpg></p><p><img src=/images/2021_03_12_12_17_53_637x171.jpg alt=/images/2021_03_12_12_17_53_637x171.jpg></p><p><img src=/images/2021_03_12_12_18_08_647x302.jpg alt=/images/2021_03_12_12_18_08_647x302.jpg></p><p><img src=/images/2021_03_12_12_18_26_676x147.jpg alt=/images/2021_03_12_12_18_26_676x147.jpg></p><p><img src=/images/2021_03_12_12_18_49_698x344.jpg alt=/images/2021_03_12_12_18_49_698x344.jpg></p><p><img src=/images/2021_03_12_12_19_03_659x170.jpg alt=/images/2021_03_12_12_19_03_659x170.jpg></p><p>外面ping:</p><pre><code>ubuntu@ubuntu:~$ ping 192.168.122.30
PING 192.168.122.30 (192.168.122.30) 56(84) bytes of data.
64 bytes from 192.168.122.30: icmp_seq=1 ttl=64 time=0.941 ms
64 bytes from 192.168.122.30: icmp_seq=2 ttl=64 time=0.499 ms

</code></pre><p>8-> 设置root password.</p><p>如果无其他设置，则直接安装</p><p><img src=/images/2021_03_12_12_21_21_705x347.jpg alt=/images/2021_03_12_12_21_21_705x347.jpg></p><p>安装过程:</p><p><img src=/images/2021_03_12_12_22_16_651x345.jpg alt=/images/2021_03_12_12_22_16_651x345.jpg></p><p>安装完毕后，登陆:</p><pre><code>$ ssh root@192.168.122.30
The authenticity of host '192.168.122.30 (192.168.122.30)' can't be established.
ECDSA key fingerprint is SHA256:wC8hcKiDjbz1+l9MAIUWMZju0evX4ZAIQjz+GPzEL4I.
Are you sure you want to continue connecting (yes/no/[fingerprint])? yes
Warning: Permanently added '192.168.122.30' (ECDSA) to the list of known hosts.

Authorized users only. All activities may be monitored and reported.
root@192.168.122.30's password: 

Authorized users only. All activities may be monitored and reported.
Web console: https://localhost:9090/ or https://192.168.122.30:9090/

Last failed login: Thu Apr  2 03:46:11 CST 2020 from 192.168.122.1 on ssh:notty
There was 1 failed login attempt since the last successful login.
[root@localhost ~]# 

</code></pre><p>部署完RONG后，检查:</p><pre><code>[root@localhost Rong]# kubectl get node
NAME     STATUS   ROLES    AGE     VERSION
test01   Ready    master   9m48s   v1.18.8
[root@localhost Rong]# uname -a
Linux localhost.localdomain 4.19.90-17.ky10.aarch64 #1 SMP Sun Jun 28 14:27:40 CST 2020 aarch64 aarch64 aarch64 GNU/Linux
[root@localhost Rong]# cat /etc/issue

Authorized users only. All activities may be monitored and reported.

</code></pre><p>pod对应的指标:</p><pre><code>[root@localhost ~]# kubectl get pods --all-namespaces
NAMESPACE     NAME                                          READY   STATUS              RESTARTS   AGE
kube-system   calico-kube-controllers-f874b4f5f-846zc       0/1     CrashLoopBackOff    12         24m
kube-system   calico-node-4d869                             0/1     CrashLoopBackOff    12         25m
kube-system   coredns-dff8fc7d-f2n26                        0/1     ContainerCreating   0          23m
kube-system   dns-autoscaler-7b85bccb5f-264cz               0/1     ContainerCreating   0          23m
kube-system   kube-apiserver-test01                         1/1     Running             1          28m
kube-system   kube-controller-manager-test01                1/1     Running             1          28m
kube-system   kube-proxy-q6mnw                              1/1     Running             1          28m
kube-system   kube-scheduler-test01                         1/1     Running             1          28m
kube-system   kubernetes-dashboard-674bb5ff47-mw97w         0/1     ContainerCreating   0          23m
kube-system   kubernetes-metrics-scraper-54fbb4d595-64b6j   0/1     ContainerCreating   0          23m
kube-system   metrics-server-757968d55d-62czd               0/2     ContainerCreating   0          21m
kube-system   tiller-deploy-75dc954ffd-psj68                0/1     ContainerCreating   0          22m
</code></pre><p>同样的vm在华为的HI1616机器上表现正常。可见YINHE 麒麟 V10的系统bug较多，可能未曾适配过完整的硬件列表。</p></div><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/blog/2021/02/22/workingtipsonha/>WorkingTIPSOnHA</a></h1><span class=post-date>Feb 22, 2021<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><p>目的: 设置RONG服务器的高可用性.</p><p>Install ipvsadm for every node:</p><pre><code># apt-get install -y ipvsadm
</code></pre></div><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/blog/2021/02/13/linuxtips12/>LinuxTips12</a></h1><span class=post-date>Feb 13, 2021<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><h3 id=1-vagrant-libvirt>1. vagrant-libvirt</h3><p>vagrant 2.2.14版中的一个包依赖BUG导致几乎所有的插件都没法装。解决方案是回归到旧版本的vagrant后安装vagrant-libvirt:</p><pre><code>$ sudo pacman -U /var/cache/pacman/pkg/vagrant-2.2.10-2-x86_64.pkg.tar.zst
$ vagrant --version
Vagrant 2.2.10
</code></pre><p>Install <code>vagrant-libvirt</code> via:</p><pre><code>$ vagrant plugin install vagrant-libvirt  --plugin-clean-sources --plugin-source  https://mirrors.tuna.tsinghua.edu.cn/rubygems/ --debug
$ vagrant plugin install vagrant-mutate  --plugin-clean-sources --plugin-source  https://mirrors.tuna.tsinghua.edu.cn/rubygems/ --debug
</code></pre><p>Examine the installed vagrant plugins:</p><pre><code>$ vagrant plugin list
vagrant-libvirt (0.3.0, global)
vagrant-mutate (1.2.0, global)
</code></pre><h3 id=2-ignore-pkg-globally>2. Ignore PKG globally</h3><p>For ignoring some package in archlinux&rsquo;s pacman upgrade, do following:</p><pre><code>$ sudo vim /etc/pacman.conf
IgnorePkg   = vagrant
</code></pre><p>Then in next <code>pacman -Syu --noconfirm</code> we will ignore vagrant.</p><h3 id=3-enable-dmesg>3. Enable dmesg</h3><p>Enable dmesg for normal user:</p><pre><code># sudo sysctl kernel.dmesg_restrict=0
</code></pre><h3 id=4-dockerio启动panic>4. docker.io启动panic</h3><p>现象: systemctl restart docker报错无法启动，查看原因怀疑是containerd问题，</p><pre><code># journalctl -xeu containerd&gt;kkkk.txt
# cat kkkk.txt
</code></pre><p>在输出的日志中发现<code>invalid page type: xx: xx</code>问题，此时直接<code>apt-get purge</code>掉所有和docker/containerd相关的包，而后删除<code>/var/lib/containerd</code>目录, 问题得以解决。</p><h3 id=5-system-installation-time>5. System Installation Time</h3><p>Detect the system installation time via:</p><pre><code># ls -lact --full-time /etc |tail
</code></pre><h3 id=6-disable-fedora-initial-setup>6. disable fedora initial-setup</h3><p>via:</p><pre><code># systemctl stop initial-setup &amp;&amp; systemctl disable initial-setup
</code></pre><h3 id=7-python3s-simplehttpserver>7. python3&rsquo;s SimpleHTTPServer</h3><p>via:</p><pre><code>$ python3 -m http.server 8888
</code></pre><h3 id=8-curl-and-tar-xzvf>8. curl and tar xzvf</h3><p>via:</p><pre><code>curl www.xxxxx.com/kkk.tar.gz | tar xzvf
</code></pre><h3 id=9-on-install-scrot>9. On install scrot</h3><p>Missing libgiblib.so.1:</p><pre><code>$ find /usr -name libgiblib.so.1 Find this file in the location
/usr/local/lib/libgiblib.so.1 
 $ cat /etc/ld.so.conf View the current library load path to see if this file is included
include ld.so.conf.d/*.conf 
 $ echo &quot;/usr/local/lib&quot; &gt;&gt; /etc/ld.so.conf Add library path 
 $ ldconfig After loading the library file, scrot is used normally. 
 $ scrot --help View scrot help 
Usage : scrot [OPTIONS]... [FILE] 
  Where FILE is the target file for the screenshot. 
</code></pre><h3 id=10-gnome-3-add-hotkey>10. gnome 3 add hotkey</h3><p>Via adding hotkey <code>system->settings</code>:</p><p><img src=/images/2021_04_12_10_35_48_538x140.jpg alt=/images/2021_04_12_10_35_48_538x140.jpg></p><h3 id=11-install-awesome-on-centos7>11. Install awesome on centos7</h3><p>via:</p><pre><code>#
# Copy and paste the lines below to install the 64-bit EL 7.x set.
#
BOOTSTRAP_TAR=&quot;bootstrap-el7-trunk-x86_64-20200724.tar.gz&quot;
BOOTSTRAP_SHA=&quot;478d2e30f150712a851f8f4bcff7f60026f65c9e&quot;

# Download the bootstrap kit to the current directory.
curl -O https://pkgsrc.joyent.com/packages/Linux/el7/bootstrap/${BOOTSTRAP_TAR}

# Verify the SHA1 checksum.
echo &quot;${BOOTSTRAP_SHA}  ${BOOTSTRAP_TAR}&quot; &gt;check-shasum
sha1sum -c check-shasum

# Verify PGP signature.  This step is optional, and requires gpg.
curl -O https://pkgsrc.joyent.com/packages/Linux/el7/bootstrap/${BOOTSTRAP_TAR}.asc
curl -sS https://pkgsrc.joyent.com/pgp/56AAACAF.asc | gpg2 --import
gpg2 --verify ${BOOTSTRAP_TAR}{.asc,}

# Install bootstrap kit to /usr/pkg
sudo tar -zxpf ${BOOTSTRAP_TAR} -C /

## Add paths
#$ PATH=/usr/pkg/sbin:/usr/pkg/bin:$PATH
#$ MANPATH=/usr/pkg/man:$MANPATH
</code></pre><p>Then use pkgin for installing awesome:</p><pre><code># pkgin -y install awesome
</code></pre><h3 id=12-install-rdesktopsmplayer>12. Install rdesktop/smplayer</h3><p>Install rdesktop/smplayer in centos7:</p><pre><code>sudo rpm --import http://li.nux.ro/download/nux/RPM-GPG-KEY-nux.ro 
sudo rpm -Uvh http://li.nux.ro/download/nux/dextop/el7/x86_64/nux-dextop-release-0-1.el7.nux.noarch.rpm    
sudo yum install rdesktop
</code></pre><h3 id=13-rsync-centos-7-repo>13. rsync centos 7 repo</h3><p>via:</p><pre><code># rsync -vrt   rsync://rsync.mirrors.ustc.edu.cn/repo/centos/7/updates/x86_64/ .
</code></pre><h3 id=14-knoppix-ssh>14. knoppix ssh</h3><p>Start sshd via:</p><pre><code># /etc/init.d/ssh start
# passwd root

</code></pre><h3 id=15-rpm-belongs-to-which-repo>15. rpm belongs to which repo</h3><p>via :</p><pre><code>$ repoquery -i rpmname
</code></pre><h3 id=16-sftp-with-port>16. sftp with port</h3><p>via:</p><pre><code>sftp -oPort=port_number host_name

</code></pre><h3 id=17-lxc-proxy>17. lxc proxy</h3><p>forwarding from host to lxc containers via:</p><pre><code>lxc config device add mycontainer myport80 proxy listen=tcp:0.0.0.0:80 connect=tcp:127.0.0.1:80

</code></pre><h3 id=18-lxc-mount-devicesda>18. lxc mount device(sda)</h3><p>via:</p><pre><code>  lxc config device add teledb-node-test1  myrawdisk unix-block source=/dev/vda
  lxc config device add teledb-node2  myrawdisk unix-block source=/dev/vda
</code></pre><h3 id=19-lxc-add-config-dynamically>19. lxc add config dynamically</h3><p>via:</p><pre><code> lxc config set mycontainer raw.lxc=&quot;lxc.cgroup.devices.allow = c 10 237&quot; raw.lxc=&quot;lxc.cgroup.devices.allow = b 7 *&quot;
$ lxc config show mycontainer
...
raw.lxc: lxc.cgroup.devices.allow = b 7 *
...
$ 
</code></pre><h3 id=20vim-中文乱码>20.vim 中文乱码</h3><p>Set following in ~/.vimrc:</p><pre><code>set fileencodings=utf-8,gb2312,gb18030,gbk,ucs-bom,cp936,latin1
set enc=utf8
set fencs=utf8,gbk,gb2312,gb18030
</code></pre><h3 id=21-lxc-set-static-ip>21. lxc set static ip</h3><p>via:</p><pre><code># lxc stop gitlabinstance
# lxc network attach lxdbr0 gitlabinstance eth0 eth0
# lxc config device set gitlabinstance eth0 ipv4.address 10.222.125.125
# lxc start gitlabinstance
</code></pre><h3 id=22-lxc-set-directoy>22. lxc set directoy</h3><p>add directory to running lxc instance:</p><pre><code>lxc config device add Solr4StandAlone sdb disk source=/var/lib/lxc/Solr4StandAlone/rootfs/data path=mnt/ssd/solr_data
</code></pre><h3 id=23-lxc-set-priviledge>23. lxc set priviledge</h3><p>For mkdir in external disk:</p><pre><code>lxc config set lxc105PERF security.privileged=true
</code></pre><h3 id=24-set-multiple-parameters>24. set multiple parameters</h3><p>via:</p><pre><code>printf 'lxc.cgroup.devices.allow = c 10 237\nlxc.cgroup.devices.allow = b 7 *' | lxc config set mycontainer raw.lxc -
</code></pre><h3 id=25-limit-lxcbr0-dhcp-range>25. limit lxcbr0 dhcp range</h3><p>via:</p><pre><code>lxc network set lxdbr0 ipv4.dhcp.ranges 10.0.8.2-10.0.8.200
</code></pre><h3 id=26-lxc-profile-issues>26. lxc profile issues</h3><p>solved via:</p><pre><code>lxc exec mycontainer -- sudo --user ubuntu --login
</code></pre><h3 id=27-lxc-set-ulimit>27. lxc set ulimit</h3><p>via:</p><pre><code>lxc config set mycontainer limits.kernel.nofile 200000
lxc restart mycontainer
</code></pre><h3 id=28-snap-disable-lxd>28. snap disable lxd</h3><p>via;</p><pre><code># snap disable lxd
</code></pre><h3 id=29-find-which-command>29. find which command</h3><p>via:</p><pre><code> yum whatprovides lsb_release
</code></pre><h3 id=30-get-public-ip>30. get public ip</h3><p>via:</p><pre><code>$ curl 'https://api.ipify.org?format=json'
{&quot;ip&quot;:&quot;144.34.187.48&quot;}
</code></pre><h3 id=31-downgrader-qemu-in-archlinux>31. downgrader qemu in ArchLinux</h3><p>Install yay for replacing yaourt, yaourt is too old and will be removed from my tools:</p><pre><code>$ git clone https://aur.archlinux.org/yay-git.git
$ cd yay-git
$ maekpkg -si
$ yay -S downgrader-git
$ downgrader qemu
$ qemu-system-x86_64 --version
QEMU emulator version 5.2.0
Copyright (c) 2003-2020 Fabrice Bellard and the QEMU Project developers
$ sudo vim /etc/pacman.conf
IgnorePkg   = qemu
</code></pre><h3 id=32-snap-set-proxy>32. snap set proxy</h3><p>via:</p><pre><code>snap set system proxy.http=&quot;http://&lt;proxy_addr&gt;:&lt;proxy_port&gt;&quot;
snap set system proxy.https=&quot;http://&lt;proxy_addr&gt;:&lt;proxy_port&gt;&quot;
</code></pre><h3 id=33-lxc-start-vm>33. lxc start vm</h3><p>Specify vm&rsquo;s cpus and memory limits:</p><pre><code>lxc init a4e0a3e72f3b ubuntu1804
lxc config device override ubuntu1804 root size=15GB
lxc config set ubuntu1804 limits.cpu 4
lxc config set ubuntu1804 limits.memory 16GB
echo -n '-device vfio-pci,host=40:00.0' | lxc config set ubuntu1804 raw.qemu -
lxc start ubuntu1804
</code></pre><h3 id=34-lxc-set-proxy>34. lxc set proxy</h3><p>via:</p><pre><code> lxc config set core.proxy_https http://xxx.xxx.xxx.xx:8118
  lxc config set core.proxy_http http://xxx.xxx.xxx.xx:8118

</code></pre><h3 id=35-lxc-start-vm>35. lxc start vm</h3><p>via followinig commands:</p><pre><code>lxc launch images:centos/8 centos --vm
lxc launch images:centos/8 centos --vm --config limits.cpu=4 --config limits.memory=16GB
lxc launch images:ubuntu/bionic ubuntu1804 --vm
</code></pre><p>vfio items(not ok):</p><pre><code>echo -n '-device vfio-pci,host=0000:3e:00.0,id=hostdev0' | lxc config set king4 raw.qemu -
</code></pre><h3 id=36-lxd-spice-connection>36. lxd spice connection</h3><p>via:</p><pre><code># remote-viewer spice+unix:///var/snap/lxd/common/lxd/logs/win10/qemu.spice
</code></pre><p>Forward via socat:</p><pre><code># socat TCP-LISTEN:9777,reuseaddr,fork UNIX-CLIENT:/var/snap/lxd/common/lxd/logs/win10/qemu.spice
</code></pre><p>access via:</p><pre><code># remote-viewer spice://localhost:9777
</code></pre><h3 id=37-undo-commit>37. undo commit</h3><p>via:</p><pre><code>git reset HEAD~
</code></pre><h3 id=38-zerotier-one-issue>38. zerotier-one issue</h3><p>In ArchLinux, cause the default tun won&rsquo;t load at startup, it fails on start,
modified via:</p><pre><code># vim /etc/modprobe.d/modprobe.conf
options tun
</code></pre><p>Save and restart the service, now zero-tier works properly.</p><h3 id=39-ssh-via-jump>39. ssh via jump</h3><p>Reverse ssh tunnel via(<code>xxx.xxx.xxx.xxx</code> is my own public ip):</p><pre><code>ssh -o GatewayPorts=true -fNTR *:4381:localhost:22 -p 12222 root@xxx.xxx.xxx.xxx
</code></pre><p>After ssh forwardinig to local, ssh via jump. :</p><pre><code>ssh -J root@192.168.1.2 -p4381 ctyun@localhost
</code></pre><h3 id=40-fake-usb>40. fake usb</h3><p>via:</p><pre><code>sudo modprobe dummy_hcd
 sudo modprobe g_mass_storage file=/media/sda5/16G.img idVendor=0x1d6b idProduct=0x0104 iManufacturer=Myself iProduct=VirtualBlockDevice iSerialNumber=123
</code></pre><p>Then you could directly use this usb disk .</p><h3 id=41-sed-remove-last-line>41. sed remove last line</h3><p>via:</p><pre><code># sed '$d' kkk.txt
</code></pre><h3 id=42-run-qemu-in-centos7>42. run qemu in centos7</h3><p>via:</p><pre><code> /usr/libexec/qemu-kvm -net nic -net user,hostfwd=tcp::2228-:22 -hda ./ubutu200420200630.img -boot d -m 2048 --enable-kvm -vga virtio
</code></pre><p>Then we could login with <code>ssh -p2228 root@localhost</code> for login into vm, in vm
using 10.0.2.X for operations.</p><h3 id=43-lxd-cluster-mode>43. lxd cluster mode</h3><p>edge01 initialization process:</p><pre><code># lxd init
Would you like to use LXD clustering? (yes/no) [default=no]: yes
What name should be used to identify this node in the cluster? [default=edge1]: 
What IP address or DNS name should be used to reach this node? [default=192.168.100.208]: 
Are you joining an existing cluster? (yes/no) [default=no]: 
Setup password authentication on the cluster? (yes/no) [default=no]: yes
Trust password for new clients: 
Again: 
Do you want to configure a new local storage pool? (yes/no) [default=yes]: 
Name of the storage backend to use (zfs, btrfs, dir, lvm) [default=zfs]: 
Create a new ZFS pool? (yes/no) [default=yes]: 
Would you like to use an existing empty block device (e.g. a disk or partition)? (yes/no) [default=no]: 
Size in GB of the new loop device (1GB minimum) [default=30GB]: 
Do you want to configure a new remote storage pool? (yes/no) [default=no]: 
Would you like to connect to a MAAS server? (yes/no) [default=no]: 
Would you like to configure LXD to use an existing bridge or host interface? (yes/no) [default=no]: yes
Name of the existing bridge or host interface: eth0
Would you like stale cached images to be updated automatically? (yes/no) [default=yes] 
Would you like a YAML &quot;lxd init&quot; preseed to be printed? (yes/no) [default=no]: 
</code></pre><h3 id=44-apt-proxy-via-sock5>44. apt proxy via sock5</h3><p>via:</p><pre><code>Acquire::http::proxy &quot;socks5h://server:port&quot;;

</code></pre><h3 id=45-proxy-related>45. proxy related</h3><p>via:</p><pre><code>https://gist.github.com/lanceliao/75c368f16238ae4c741d
https://github.com/fanchangyong/blog/issues/22
https://www.shangyexinzhi.com/article/485648.html
https://thenewstack.io/the-use-case-for-kubernetes-at-the-edge/
https://blog.ismisv.com/2015/09/raspberry-pi-as-a-fucking-gfw-gateway/
https://www.youtube.com/watch?v=cB8fNytQXTY
https://www.aularon.com/linux/transparent-proxy-via-another-computer/
https://www.cnblogs.com/develon/p/11830726.html
</code></pre><h3 id=46-disable-ipv6>46. Disable ipv6</h3><p>in ubuntu, via:</p><pre><code># sudo vim /etc/default/grub
GRUB_CMDLINE_LINUX_DEFAULT=&quot;quiet splash ipv6.disable=1&quot;
GRUB_CMDLINE_LINUX=&quot;ipv6.disable=1&quot;
# sudo update-grub
</code></pre><h3 id=47-snap-install-failed>47. snap install failed</h3><p>Tested via:</p><pre><code>curl https://api.snapcraft.io/api/v1/snaps/sections
</code></pre><h3 id=48-completely-disable-nvidia-card>48. Completely disable nvidia card</h3><p>In archlinux, via:</p><pre><code>$ sudo systemctl enable nvidia-xrun-pm
</code></pre><h3 id=49-recover-sudo>49. recover sudo</h3><p>via:</p><pre><code>chown root:root /usr/bin/sudo &amp;&amp; chmod 4755 /usr/bin/sudo
</code></pre><p>Solved problem:</p><pre><code>sudo: /usr/bin/sudo must be owned by uid 0 and have the setuid bit set
</code></pre><h3 id=50-sway-in-archlinux>50 sway in archlinux</h3><p>via:</p><pre><code>add LIBSEAT_BACKEND=logind to my /etc/environment
useradd -m xxxx
sudo passwd xxxx
Then login with xxxx
sway
</code></pre><h3 id=51-keep-mosue-moving>51. keep mosue moving</h3><p>via:</p><pre><code>sudo snap install keep-presence

Then run it:

keep-presence --seconds 30
</code></pre><h3 id=52-k8s-profile-for-lxd>52. k8s profile for lxd</h3><p>via:</p><pre><code>name: k8s
config:
  boot.autostart: &quot;true&quot;
  linux.kernel_modules: ip_vs,ip_vs_rr,ip_vs_wrr,ip_vs_sh,ip_tables,ip6_tables,netlink_diag,nf_nat,overlay,br_netfilter
  raw.lxc: |
    lxc.apparmor.profile=unconfined
    lxc.mount.auto=proc:rw sys:rw cgroup:rw
    lxc.cgroup.devices.allow=a
    lxc.cap.drop=
  security.nesting: &quot;true&quot;
  security.privileged: &quot;true&quot;
description: &quot;&quot;
devices:
  aadisable:
    path: /sys/module/nf_conntrack/parameters/hashsize
    source: /sys/module/nf_conntrack/parameters/hashsize
    type: disk
  #aadisable1:
  #  path: /sys/module/apparmor/parameters/enabled
  #  source: /dev/null
  #  type: disk
  aadisable2:
    path: /dev/kmsg
    source: /dev/kmsg
    type: disk
  aadisable3:
    path: /sys/fs/bpf
    source: /sys/fs/bpf
    type: disk

</code></pre><h3 id=53-dnscrypt-proxy-issue>53. dnscrypt-proxy issue</h3><p>Changing the <code>dnscrypt-proxy</code> after ccp 100years birthday, I have to change the proxy port from 1080(sslocal) to 2x1xx(v2ray)</p><h3 id=54-lxd-use-external-ceph>54. lxd use external ceph</h3><p>via:</p><pre><code>snap set lxd ceph.external=true
systemctl reload snap.lxd.daemon
</code></pre><h3 id=55-gucamole-xrdp-issue>55. gucamole xrdp issue</h3><p>via:</p><pre><code>cd /tmp/
curl -Lo 'freerdp2libplugins.zip' 'https://community.bitnami.com/uploads/default/original/3X/b/9/b9c8a1945544603988ffd12e0bc2b9377d1653e2.zip'
unzip freerdp2libplugins.zip
sudo mv freerdp2 /usr/lib/x86_64-linux-gnu/
</code></pre><h3 id=56-python-missing>56. python missing</h3><p>When building android, meet: <code>/usr/bin/env: python: No such file or directory</code>
solved via:</p><pre><code># sudo apt-get install python-is-python3
</code></pre><h3 id=57-ubuntu18045-python2-default>57. ubuntu18.04.5 python2 default</h3><p>via:</p><pre><code>update-alternatives --install /usr/bin/python python /usr/bin/python2 10
</code></pre><p>then we could build android.</p><h3 id=58-varlogjournal-too-big>58. /var/log/journal too big</h3><p>shrink via:</p><pre><code># journalctl --vacuum-size=100M
</code></pre><h3 id=59-xmind>59. XMind</h3><p>Install xmind on archlinux via:</p><pre><code>$ yay xmind
8 aur/xmind 3.7.9+8update9-1 (+30 0.03) (Installed)
#  vim /usr/share/xmind/XMind/XMind.ini
-vm
/usr/lib/jvm/java-8-openjdk/jre/bin
-configuration
.....
</code></pre><p>Then we could use XMind.</p><h3 id=60-android-building>60. Android building</h3><p>Problem:</p><pre><code>....
No DEX files specified
...
</code></pre><p>via:</p><pre><code>$ make clean-apache-xml
$ make apache-xml
</code></pre><p>Then:</p><pre><code># make clean-ims-common &amp;&amp; make ims-common &amp;&amp; make apache-xml &amp;&amp; m -j12 iso_img
</code></pre><h3 id=61-install-fcitx5>61. Install fcitx5</h3><p>Replace fcitx4 with fcitx5 with:</p><pre><code>$ sudo pacman -R fcitx-configtool fcitx-googlepinyin fcitx-libpinyin fcitx-qt4 fcitx-qt5
$ sudo pacman -S fcitx5
$ sudo pacman -S fcitx5-chinese-addons
$ sudo pacman -S fcitx5-qt fcitx5-gtk
$ sudo pacman -S fcitx5-configtool
</code></pre><h3 id=62-hostapd>62. hostapd</h3><p>In shida box:</p><pre><code># git clone https://github.com/lwfinger/rtl8188eu.git
# cd rtl8188eu
# make all
# sudo make install
</code></pre><h3 id=63-driver-in-anbox>63. driver in anbox</h3><p>Added lxc device via:</p><pre><code>lxc-device -n android add /dev/ashmem

</code></pre><h3 id=64-proot-working-tips>64. PRoot working Tips</h3><p>Install termux from F-droid, then:</p><pre><code>pkg install proot
pkg install proot-distro
proot-distro install archlinux
</code></pre><h3 id=65-check-if-android-booted>65. Check if android booted</h3><p>via:</p><pre><code># getprop sys.boot_completed
</code></pre><h3 id=67-overwrite-cmd-for-docker>67. Overwrite cmd for docker</h3><p>via:</p><pre><code>#  docker run [other options] --entrypoint '/bin/sh' $IMAGE -c 'npm link gulp gulp-sass gulp-sourcemaps'
</code></pre><h3 id=68-update-python-for-ubuntu1804>68. update python for ubuntu18.04</h3><p>via:</p><pre><code># update-alternatives --config python
</code></pre><h3 id=69-gdm-vs-lightdm>69. gdm vs lightdm</h3><p>Changing from ubuntu:</p><pre><code>sudo dpkg-reconfigure gdm3

</code></pre><h3 id=70-start-anbox-in-ubuntu>70. Start anbox in ubuntu</h3><p>exited in ubuntu18.04, solved via:</p><pre><code>export EGL_PLATFORM=x11
anbox.appmgr
</code></pre><h3 id=71-rsync-ignore-directory>71. rsync ignore directory</h3><p>via:</p><pre><code>rsync -av --progress aic-cg/ /root/fenxi/ --exclude workdir

(aic-cg)  -----&gt;  /root/fenxi
source   ----&gt;   dest
</code></pre><h3 id=72-redsocks-iptables-issue>72. redsocks iptables issue</h3><p>On Ubuntu18.04, solved via:</p><pre><code>rm /usr/sbin/iptables
ln -s /usr/sbin/iptables-legacy /usr/sbin/iptables
</code></pre><h3 id=73-dd-write-xz-to-rpi>73. dd write xz to rpi</h3><p>Via:</p><pre><code>xz -d &lt; /home/dash/Downloads/ubuntu-20.04.3-preinstalled-server-arm64+raspi.img.xz - | dd of=/dev/sdb &amp;&amp; sync
</code></pre><h3 id=74-virsh-console>74. virsh console</h3><p>via:</p><pre><code>virsh ttyconsole vuserv
</code></pre><p>Enable grub output via:</p><pre><code>#  vim /etc/default/grub
GRUB_DISTRIBUTOR=`lsb_release -i -s 2&gt; /dev/null || echo Debian`
GRUB_TERMINAL_INPUT=&quot;console serial&quot;
GRUB_TERMINAL_OUTPUT=&quot;gfxterm serial&quot;
GRUB_SERIAL_COMMAND=&quot;serial --unit=0 --speed=115200&quot;
GRUB_CMDLINE_LINUX_DEFAULT=&quot;console=tty0 console=ttyS0,115200 maybe-ubiquity&quot;
GRUB_CMDLINE_LINUX=&quot;&quot;
# update-grub2
</code></pre><h3 id=75-logcat>75. logcat</h3><p>view only crash logs:</p><pre><code>logcat -b crash
</code></pre><h3 id=76-lxc-enter-container>76. lxc enter container</h3><p>via:</p><pre><code>lxc-attach -n Name -- command
</code></pre><h3 id=77-apt-fast>77. apt-fast</h3><p>via:</p><pre><code>sudo add-apt-repository ppa:apt-fast/stable
sudo apt-get update
sudo apt-get -y install apt-fast

</code></pre><h3 id=78-adb-tips>78. adb tips</h3><p>list all of the connected devices:</p><pre><code>adb devices
</code></pre><p>connect to specific device via:</p><pre><code>adb -s 192.168.1.41:5555 shell
</code></pre><h3 id=79-anboxredroid-preparation>79. anbox/redroid preparation</h3><p>related kernel modules should be inserted:</p><pre><code>sudo modprobe ashmem_linux
sudo modprobe binder_linux devices=binder,hwbinder,vndbinder
</code></pre><p>examine via:</p><pre><code>root@vp1:/home/dash# grep binder /proc/filesystems
nodev	binder
root@vp1:/home/dash# grep ashmem /proc/misc
121 ashmem
</code></pre><h3 id=80-pipewire>80. pipewire</h3><p>Install and enable via:</p><pre><code>$ sudo pacman install -y pipewire
$ systemctl --user enable pipewire pipewire-pulse pipewire-media-session
$ systemctl --user restart pipewire pipewire-pulse pipewire-media-session
</code></pre></div><ul class=pagination><li class=page-item><a href=/ class=page-link aria-label=First><span aria-hidden=true>&#171;&#171;</span></a></li><li class=page-item><a href=/page/31/ class=page-link aria-label=Previous><span aria-hidden=true>&#171;</span></a></li><li class=page-item><a class=page-link href=/>1</a></li><li class=page-item><a class=page-link href=/page/2/>2</a></li><li class=page-item><a class=page-link href=/page/3/>3</a></li><li class="page-item disabled"><span aria-hidden=true>&nbsp;&mldr;&nbsp;</span></li><li class=page-item><a class=page-link href=/page/31/>31</a></li><li class="page-item active"><a class=page-link href=/page/32/>32</a></li><li class=page-item><a class=page-link href=/page/33/>33</a></li><li class="page-item disabled"><span aria-hidden=true>&nbsp;&mldr;&nbsp;</span></li><li class=page-item><a class=page-link href=/page/233/>233</a></li><li class=page-item><a href=/page/33/ class=page-link aria-label=Next><span aria-hidden=true>&#187;</span></a></li><li class=page-item><a href=/page/233/ class=page-link aria-label=Last><span aria-hidden=true>&#187;&#187;</span></a></li></ul></div></div><script src=http://purplepalmdash.github.io/js/highlight.pack.js></script><script>hljs.initHighlightingOnLoad();</script></body></html>