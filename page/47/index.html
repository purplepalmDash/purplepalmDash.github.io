<!doctype html><html xmlns=http://www.w3.org/1999/xhtml xml:lang=en lang=en-us><head><meta name=generator content="Hugo 0.64.0"><link href=http://gmpg.org/xfn/11 rel=profile><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><title>Dash &#183; Dash</title><link rel=stylesheet href=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap-theme.min.css><link rel=stylesheet href="https://purplepalmdash.github.io/css/poole.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/hyde.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/poole-overrides.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/hyde-overrides.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/hyde-a.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/custom-additions.css?ref=abc124"><link rel=stylesheet href=https://purplepalmdash.github.io/css/highlight/googlecode.css><link rel=stylesheet href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.3.0/css/font-awesome.min.css><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.5/styles/docco.min.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/1.10.2/jquery.min.js></script><script type=text/javascript src=/js/html2canvas.js></script><script type=text/javascript>function genPostShot(){var rightNow=new Date();var imageName=rightNow.toISOString().slice(0,16).replace(/(-)|(:)|(T)/g,"");imageName+='.jpg'
html2canvas(document.getElementsByClassName('post'),{background:'#FFFFFF',onrendered:function(canvas){$('#test').attr('href',canvas.toDataURL("image/jpeg"));$('#test').attr('download',imageName);$('#test')[0].click();}});};</script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.5/highlight.min.js></script><script>hljs.initHighlightingOnLoad();</script><link rel=apple-touch-icon-precomposed sizes=144x144 href="http://purplepalmdash.github.io/touch-icon-144-precomposed.png?ref=abc124"><link href="http://purplepalmdash.github.io/favicon.png?ref=abc124" rel=icon><link href=%7balternate%20%7bRSS%20application/rss+xml%20%20index%20alternate%20%20false%20false%20true%20false%20false%200%7d%20/index.xml%20http://purplepalmdash.github.io/index.xml%7d rel=alternate type=application/rss+xml title="Dash &#183; Dash"><meta name=description content><meta name=keywords content="unix,virtualization,embedded,linux"></head><body class=theme-base-0c><div class=sidebar><div class="container sidebar-sticky"><div class=sidebar-about><img src=http://purplepalmdash.github.io/images/mylogo.jpeg alt=gravatar><h1><a href=http://purplepalmdash.github.io/>很惭愧，就做了一点微小的工作</a></h1><a href=http://purplepalmdash.github.io/><p>Dash</p></a></div><ul class=sidebar-nav><li class=sidebar-nav-item><a href=http://purplepalmdash.github.io/post/>All Posts</a></li><li class=sidebar-nav-item><a href=http://purplepalmdash.github.io/categories/technology/>Technology</a></li><li class=sidebar-nav-item><a href=http://purplepalmdash.github.io/categories/life/>Life</a></li><li class=sidebar-nav-item><a href=http://purplepalmdash.github.io/categories/linuxtips/>LinuxTips</a></li></ul><ul class=sidebar-nav><li class=sidebar-nav-item><a href=https://github.com/purplepalmdash><i class="fa fa-github-square fa-3x"></i></a><a href=https://cn.linkedin.com/in/yang-feipeng-1b909319><i class="fa fa-linkedin-square fa-3x"></i></a><a href=https://plus.google.com/u/0/106572959364703833986><i class="fa fa-google-plus-square fa-3x"></i></a><a href=https://www.facebook.com/yang.feipeng><i class="fa fa-facebook-square fa-3x"></i></a><a href=https://twitter.com/dashwillfly><i class="fa fa-twitter-square fa-3x"></i></a></li></ul></div></div><div class="content container"><div class=posts><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/blog/2019/08/21/upgradingkubespray2110/>UpgradingKubespray2110</a></h1><span class=post-date>Aug 21, 2019<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><h3 id=prepare>Prepare</h3><p>vagrant vms, install kubespray via vagrant.</p><p>Additional packages:</p><pre><code># apt-add-repository ppa:ansible/ansible
# sudo apt-get install -y netdata ntpdate ansible python-netaddr bind9 bind9utils ntp nfs-common nfs-kernel-server python-netaddr nethogs iotop
# sudo mkdir /root/static
# cd /var/cache
# find . | grep deb$ | xargs -I % cp % /root/stati
# cd /root/static
# dpkg-scanpackages . /dev/null | gzip -9c &gt; Packages.gz
# cd /root/
# tar cJvf 1804debs.tar.xz static/
</code></pre><p>scp the 1804debs.tar.xz to the <code>kube-deploy</code> role(later).</p><h3 id=modification>Modification</h3><pre><code># wget https://github.com/projectcalico/calicoctl/releases/download/v3.7.3/calicoctl-linux-amd64
# wget https://github.com/containernetworking/plugins/releases/download/v0.8.1/cni-plugins-linux-amd64-v0.8.1.tgz
</code></pre></div><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/blog/2019/08/19/thinkingoncoreos/>ThinkingOnCoreOS</a></h1><span class=post-date>Aug 19, 2019<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><h3 id=aim>AIM</h3><p>To deploy kubespray-deployed kubernetes offlinely.</p><h3 id=problems>Problems</h3><ol><li>Operating system?</li><li>How to run ansible?</li><li>How to run ssl configurations?</li><li>How to setup dns name server and pretend the docker.io/quay.io/gcr.io?</li><li>Scale up/down the cluster?</li><li>Netdata?</li><li>docker-compose based systemd configuration?</li></ol><h3 id=steps>Steps</h3><h4 id=1-environments>1. Environments</h4><p>vagrant based coreos OS.<br>From the kubespray&rsquo;s Vagrantfile, judge the coreos box file:</p><p><img src=/images/2019_08_19_11_32_29_952x262.jpg alt=/images/2019_08_19_11_32_29_952x262.jpg></p><p>Then download the latest coreos vagrant box via:</p><pre><code># wget https://stable.release.core-os.net/amd64-usr/2135.6.0/coreos_production_vagrant.box
</code></pre><h4 id=2-dns-nameserver>2. dns nameserver</h4><p>Run dns nameserver in docker.</p><pre><code># sudo docker run --name dnsmasq -d -p 53:53/udp -p 5380:8080 -v /home/core/dnsmasq.conf:/etc/dnsmasq.conf --log-opt &quot;max-size=100m&quot;  -e &quot;HTTP_USER=foo&quot;  -e &quot;HTTP_PASS=bar&quot;  --restart always  jpillora/dnsmasq
# cat dnsmasq.conf 
#dnsmasq config, for a complete example, see:
#  http://oss.segetech.com/intra/srv/dnsmasq.conf
#log all dns queries
log-queries
#dont use hosts nameservers
no-resolv
#use cloudflare as default nameservers, prefer 1^4
server=1.0.0.1
server=1.1.1.1
strict-order
#serve all .company queries using a specific nameserver
server=/company/10.0.0.1
#explicitly define host-ip mappings
address=/myhost.company/10.0.0.2
address=/portus.xxxxx.com/10.142.18.191
address=/gcr.io/10.142.18.191
address=/k8s.gcr.io/10.142.18.191
address=/quay.io/10.142.18.191
address=/elastic.co/10.142.18.191
address=/docker.elastic.co/10.142.18.191
address=/docker.io/10.142.18.191
address=/registry-1.docker.io/10.142.18.191
</code></pre><p>Later we will configure dns for <code>/etc/resolv.conf</code> in coreos.</p><h4 id=3-dns-client>3. dns client</h4><p>For configurating the client&rsquo;s dns name server, do:</p><pre><code>#  cat /etc/systemd/resolved.conf 
  #  This file is part of systemd.
  #
  #  systemd is free software; you can redistribute it and/or modify it
  #  under the terms of the GNU Lesser General Public License as published by
  #  the Free Software Foundation; either version 2.1 of the License, or
  #  (at your option) any later version.
  #
  # Entries in this file show the compile time defaults.
  # You can change settings by editing this file.
  # Defaults can be restored by simply deleting this file.
  #
  # See resolved.conf(5) for details
  
  [Resolve]
  DNS=10.142.18.191
# sudo systemctl restart systemd-resolved
</code></pre><h4 id=4-auto-index-file-server>4. auto-index file server</h4><p>systemd file could be run, just as usual.</p><h4 id=5-ansible-version>5. ansible version</h4><p>Using virtualenv for installing ansible 2.7:</p><pre><code>#  sudo apt install virtualenv
# virtualenv -p python3 env 
# source env/bin/activate
# which pip
/media/sda/coreos_kubespray/Rong/env/bin/pip
# pip install ansible==2.7.9
# which ansible
/media/sda/coreos_kubespray/Rong/env/bin/ansible
# ansible --version
ansible 2.7.9
  config file = /media/sda/coreos_kubespray/Rong/ansible.cfg
# pip install netaddr
</code></pre><h3 id=disks>Disks</h3><p>mounting the esdata disk via:</p><pre><code># vim /etc/systemd/system/media-esdata.mount 
[Unit]
Description=Mount cinder volume
Before=docker.service

[Mount]
What=/dev/vdb1
Where=/media/esdata
Options=defaults,noatime,noexec

[Install]
WantedBy=docker.service
# systemctl enable media-esdata.mount
</code></pre><p>Then creating the filesystem on <code>/dev/vdb1</code>, your mounting point will be ok.</p></div><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/blog/2019/08/12/workingtipsonofflineopenshift/>WorkingTipsOnOfflineOpenshift</a></h1><span class=post-date>Aug 12, 2019<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><h3 id=os-preparation>OS Preparation</h3><p>Centos 7.6 OS, installed via:</p><pre><code>CentOS-7-x86_64-Everything-1810.iso
</code></pre><p>Download the source code from:</p><pre><code>https://gitee.com/xhua/OpenshiftOneClick
</code></pre><p>Corresponding docker images:</p><pre><code>docker.io/redis:5
docker.io/openshift/origin-node:v3.11.0
docker.io/openshift/origin-control-plane:v3.11.0
docker.io/openshift/origin-haproxy-router:v3.11.0
docker.io/openshift/origin-deployer:v3.11.0
docker.io/openshift/origin-pod:v3.11.0
docker.io/rabbitmq:3.7-management
docker.io/mongo:4.1
docker.io/memcached:1.5
quay.io/kubevirt/kubevirt-web-ui-operator:latest
docker.io/xhuaustc/openldap-2441-centos7:latest
quay.io/kubevirt/kubevirt-web-ui:v2.0.0
docker.io/perconalab/pxc-openshift:latest
docker.io/tomcat:8.5-alpine
docker.io/centos/postgresql-95-centos7:latest
docker.io/centos/mysql-57-centos7:latest
docker.io/centos/nginx-112-centos7:latest
docker.io/curiouser/dubbo_zookeeper:v1
docker.io/xhuaustc/logstash:6.6.1
docker.io/xhuaustc/kibana:6.6.1
docker.io/xhuaustc/elasticsearch:6.6.1
docker.io/openshift/jenkins-2-centos7:latest
docker.io/openshift/origin-docker-registry:v3.11.0
docker.io/openshift/jenkins-agent-maven-35-centos7:v4.0
docker.io/openshift/origin-console:v3.11.0
docker.io/sonatype/nexus3:3.14.0
docker.io/gitlab/gitlab-ce:11.4.0-ce.0
docker.io/openshift/origin-web-console:v3.11.0
docker.io/cockpit/kubernetes:latest
docker.io/xhuaustc/apolloportal:latest
docker.io/xhuaustc/apolloconfigadmin:latest
docker.io/xhuaustc/nfs-client-provisioner:latest
docker.io/blackcater/easy-mock:1.6.0
docker.io/perconalab/proxysql-openshift:0.5
docker.io/xhuaustc/selenium:3
docker.io/xhuaustc/zalenium:3
docker.io/xhuaustc/etcd:v3.2.22
docker.io/openshiftdemos/gogs:0.11.34
docker.io/openshiftdemos/sonarqube:6.7
docker.io/xhuaustc/openshift-kafka:latest
docker.io/redis:3.2.3-alpine
docker.io/kubevirt/virt-api:v0.19.0
docker.io/kubevirt/virt-controller:v0.19.0
docker.io/kubevirt/virt-handler:v0.19.0
docker.io/kubevirt/virt-operator:v0.19.0
</code></pre><h3 id=servers>Servers</h3><h3 id=rpm-server>rpm server</h3><p>ISO as a rpm server.</p><p>offline iso rpm server.</p><pre><code># vim files/all.repo
[openshift]
name=openshift
baseurl=http://192.192.189.1/ocrpmpkgs/
enabled=1
gpgcheck=0

[openshift1]
name=openshift1
baseurl=http://192.192.189.1:8080
enabled=1
gpgcheck=0
</code></pre><h4 id=simple-https-server>Simple https server</h4><p>Create a new folder and generate pem files under this folder:</p><pre><code># openssl req -new -x509 -keyout server.pem -out server.pem -days 365 -nodes
Common name: ssl.xxxx.com
</code></pre><p>If you set <code>ssl.xxxx.com</code>, then you visit this website via <code>https://ssl.xxxx.com:4443/index.html</code>.</p><p>Write a simple python file for serving https:</p><pre><code># vi simple-https-server.py
import BaseHTTPServer, SimpleHTTPServer
import ssl
httpd = BaseHTTPServer.HTTPServer(('localhost', 4443), SimpleHTTPServer.SimpleHTTPRequestHandler)
httpd.socket = ssl.wrap_socket (httpd.socket, certfile='./server.pem', server_side=True)
httpd.serve_forever()
# sudo python simple-https-server.py
</code></pre><p>Server folder content:</p><pre><code># ls
allinone-webconsole.css  apollo.png  easymock.png  kafka.png  nexus3.png    pxc.png     simple-https-server.py  zalenium.png
allinone-webconsole.js   dubbo.png   gogs.png      kelk.png   openldap.png  server.pem  sonarqube.svg
# cat allinone-webconsole.css 
.icon-gogs{
  background-image: url(https://ssl.xxxx.com:4443/gogs.png);
  width: 50px;
  height: 50px;
  background-size: 100% 100%;
}
.icon-sonarqube{
  background-image: url(https://ssl.xxxx.com:4443/sonarqube.svg);
  width: 80px;
  height: 50px;
  background-size: 100% 100%;
}

</code></pre><h4 id=using-simple-https-server>Using Simple https server</h4><p>Add customized domain name into <code>/etc/hosts</code>:</p><pre><code># vim /etc/hosts
192.192.189.1	ssl.xxxx.com
</code></pre><p>Add <code>server.pem</code> into the client system:</p><pre><code># yum install -y ca-certificates
# update-ca-trust force-enable
# cp server.pem /etc/pki/ca-trust/source/anchors/ssl.xxxx.com.pem
# update-ca-trust
</code></pre><h3 id=deployment>Deployment</h3><p>Two nodes, run following scripts first:</p><pre><code>#!/bin/bash

setenforce 1
selinux=$(getenforce)
if [ &quot;$selinux&quot; != Enforcing ]
then
	echo &quot;Please setlinux Enforcing&quot;
	exit 10
fi

cat &gt;/etc/sysctl.d/99-elasticsearch.conf &lt;&lt;EOF
vm.max_map_count = 262144
EOF
sysctl vm.max_map_count=262144

export CHANGEREPO=true
if [ $CHANGEREPO == true -a ! -d /etc/yum.repos.d/back ]
then
    cd /etc/yum.repos.d/; mkdir -p back; mv -f *.repo back/; cd -
    cp files/all.repo /etc/yum.repos.d/
    yum clean all
fi


current_path=`pwd`
yum localinstall tools/ansible-2.6.5-1.el7.ans.noarch.rpm -y
ansible-playbook playbook.yml --skip-tags after_task
cd $current_path/openshift-ansible-playbook
ansible-playbook playbooks/prerequisites.yml
</code></pre><p>Configuration of Master node&rsquo;s <code>config.yml</code>:</p><pre><code>---
CHANGEREPO: true
HOSTNAME: os311.test.it.example.com

</code></pre><p>Configuration of Worker node&rsquo;s <code>config.yml</code>:</p><pre><code>---
CHANGEREPO: true
HOSTNAME: os312.test.it.example.com
</code></pre><p>Then add following lines into <code>/etc/hosts</code>:</p><pre><code>192.192.189.128 os311.test.it.example.com
192.192.189.129 os312.test.it.example.com
192.192.189.1	ssl.xxxx.com
</code></pre><p>Then on master node, replace the <code>/etc/ansible/hosts</code> with our pre-defined one:</p><pre><code>.....
openshift_web_console_extension_script_urls=[&quot;https://ssl.xxxx.com:4443/allinone-webconsole.js&quot;]
openshift_web_console_extension_stylesheet_urls=[&quot;https://ssl.xxxx.com:4443/allinone-webconsole.css&quot;]

......
openshift_disable_check=memory_availability,disk_availability,package_availability,package_update,docker_image_availability,docker_storage_driver,docker_storage,package_version

.......
openshift_node_groups=[{'name': 'node-config-all-in-one', 'labels': ['node-role.kubernetes.io/master=true', 'node-role.kubernetes.io/infra=true']}, {'name': 'node-config-compute', 'labels': ['node-role.kubernetes.io/compute=true']}]
.......
[masters]
os311.test.it.example.com
[etcd]
os311.test.it.example.com

[nfs]
os311.test.it.example.com

[nodes]
os311.test.it.example.com openshift_node_group_name=&quot;node-config-all-in-one&quot;
os312.test.it.example.com openshift_node_group_name='node-config-compute'
</code></pre><p>Now run deployment:</p><pre><code>current_path=`pwd`
cd $current_path/openshift-ansible-playbook
ansible-playbook playbooks/prerequisites.yml

ansible-playbook -vvvv playbooks/deploy_cluster.yml
oc adm policy add-cluster-role-to-user cluster-admin admin

cd $current_path

ansible-playbook playbook.yml --tags install_nfs
ansible-playbook playbook.yml --tags after_task
</code></pre><p>After deployment, check the status via:</p><pre><code>[root@os311 OpenshiftOneClick]# oc get nodes
NAME                        STATUS    ROLES          AGE       VERSION
os311.test.it.example.com   Ready     infra,master   3d        v1.11.0+d4cacc0
os312.test.it.example.com   Ready     compute        3d        v1.11.0+d4cacc0
</code></pre><h3 id=kube-virt>kube-virt</h3><p>via following steps, deploy kubevirt:</p><pre><code># kubectl apply -f kubevirt-operator.yaml
# kubectl apply -f kubevirt-cr.yaml
</code></pre><p>deploy ui:</p><pre><code># cd web-ui-operator-master
# oc new-project kubevirt-web-ui
# cd deploy
# oc apply -f service_account.yaml
# oc apply -f role.yaml
# oc apply -f role_binding.yaml
# oc create -f crds/kubevirt_v1alpha1_kwebui_crd.yaml
# oc apply -f operator.yaml
# oc apply -f deploy/crds/kubevirt_v1alpha1_kwebui_cr.yaml
</code></pre><h3 id=dns-setting>DNS setting</h3><p>By following steps:</p><pre><code># vim /etc/dnsmasq.d/origin-dns.conf
address=/os311.test.it.example.com/192.192.189.128
# systemctl daemon-reload
# systemctl restart dnsmasq
</code></pre><h3 id=create-vm>Create vm</h3><p>The definition files should be modified into:</p><pre><code>apiVersion: kubevirt.io/v1alpha3
kind: VirtualMachine
metadata:
  name: testvm
spec:
  running: false
  template:
    metadata:
      labels: 
        kubevirt.io/size: small
        kubevirt.io/domain: testvm
    spec:
      domain:
        devices:
          disks:
            - name: containerdisk
              disk:
                bus: virtio
            - name: cloudinitdisk
              disk:
                bus: virtio
          interfaces:
          - name: default
            bridge: {}
        resources:
          requests:
            memory: 64M
      networks:
      - name: default
        pod: {}
      volumes:
        - name: containerdisk
          containerDisk:
            image: kubevirt/cirros-registry-disk-demo
            imagePullPolicy: IfNotPresent
        - name: cloudinitdisk
          cloudInitNoCloud:
            userDataBase64: SGkuXG4=
</code></pre><p>Thus we could launch the vms, notice we have to pull the images manually:</p><pre><code># sudo docker pull kubevirt/cirros-registry-disk-demo
# sudo docker pull index.docker.io/kubevirt/virt-launcher:v0.19.0
# sudo docker pull kubevirt/virt-launcher:v0.19.0
</code></pre></div><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/blog/2019/07/05/workingtipsonarm64centos7/>WorkingTipsOnArm64centos7</a></h1><span class=post-date>Jul 5, 2019<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><h3 id=仓库配置>仓库配置</h3><p>使用epel-7及centos7的源为默认源:</p><pre><code>[root@arm64 ~]# cat /etc/yum.repos.d/epel7.repo 
[epel]
name=Extra Packages for Enterprise Linux 7 - $basearch
baseurl=http://mirrors.aliyun.com/epel/7/$basearch
failovermethod=priority
enabled=1
gpgcheck=0
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-7
 
[epel-debuginfo]
name=Extra Packages for Enterprise Linux 7 - $basearch - Debug
baseurl=http://mirrors.aliyun.com/epel/7/$basearch/debug
failovermethod=priority
enabled=0
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-7
gpgcheck=0
 
[epel-source]
name=Extra Packages for Enterprise Linux 7 - $basearch - Source
baseurl=http://mirrors.aliyun.com/epel/7/SRPMS
failovermethod=priority
enabled=0
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-7
gpgcheck=0

[root@arm64 ~]# cat /etc/yum.repos.d/centos7.repo 


[base]
name=CentOS-7 - Base
baseurl=https://mirrors.aliyun.com/centos-altarch/7/os/$basearch/
gpgcheck=1
gpgkey=https://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-7

#released updates 
[updates]
name=CentOS-7 - Updates
baseurl=https://mirrors.aliyun.com/centos-altarch/7/updates/$basearch/
gpgcheck=1
gpgkey=https://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-7

#additional packages that may be useful
[extras]
name=CentOS-7 - Extras
baseurl=https://mirrors.aliyun.com/centos-altarch/7/extras/$basearch/
gpgcheck=1
gpgkey=https://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-7
enabled=1

#additional packages that extend functionality of existing packages
[centosplus]
name=CentOS-7 - Plus
baseurl=https://mirrors.aliyun.com/centos-altarch/7/centosplus/$basearch/
gpgcheck=1
enabled=0
gpgkey=https://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-7

</code></pre><p>基本情况:</p><pre><code>[root@arm64 ~]# uname -a
Linux arm64 4.14.0-115.el7a.0.1.aarch64 #1 SMP Sun Nov 25 20:54:21 UTC 2018 aarch64 aarch64 aarch64 GNU/Linux
[root@arm64 ~]# cat /etc/redhat-release 
CentOS Linux release 7.6.1810 (AltArch) 
</code></pre></div><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/blog/2019/07/03/building-k8s-dns-node-cache-arm64/>Building k8s-dns-node-cache-arm64</a></h1><span class=post-date>Jul 3, 2019<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><h3 id=steps>Steps</h3><p>Clone the source code from github:</p><pre><code># git clone https://github.com/kubernetes/dns.git
# git checkout tags/1.15.1 -b local_1.15.1
</code></pre><p>Modify the source code:</p><pre><code># vim Makefile
BINARIES := \
    node-cache
#    e2e \
#    ginkgo \
#    sidecar-e2e


CONTAINER_BINARIES := \
    node-cache

ARCH ?= arm64
</code></pre><p>Now building via:</p><pre><code># make build
# make containers
</code></pre><p>Will get error, now copy the generated node-cache file into destination directory:</p><pre><code># cp ./.go/bin/node-cache bin/arm64/
</code></pre><p>Edit the dnsmasq&rsquo;s Makefile via:</p><pre><code># vim images/dnsmasq/Makefile
</code></pre><p><img src=/images/2019_07_03_14_47_54_635x612.jpg alt=/images/2019_07_03_14_47_54_635x612.jpg></p><p>make will also get error, manually compile the dnsmasq:</p><pre><code># cd ./images/dnsmasq/_output/arm64/dnsmasq-2.78
# make
# cp src/dnsmasq ../docker
</code></pre><p>Now go the project root directory and make containers:</p><pre><code># make containers
# docker images  | grep dns
staging-k8s.gcr.io/k8s-dns-dnsmasq-arm64      1.15.1-dirty         fbb04ccb60e6        About an hour ago   3.63MB
staging-k8s.gcr.io/k8s-dns-node-cache-arm64   1.15.1-dirty         bf6131745b5e        About an hour ago   71.9MB
</code></pre><p>Now replace the dns-node-cache default to our own build-out version we could enable node-cache working on arm64.</p></div><ul class=pagination><li class=page-item><a href=/ class=page-link aria-label=First><span aria-hidden=true>&#171;&#171;</span></a></li><li class=page-item><a href=/page/46/ class=page-link aria-label=Previous><span aria-hidden=true>&#171;</span></a></li><li class=page-item><a class=page-link href=/>1</a></li><li class=page-item><a class=page-link href=/page/2/>2</a></li><li class=page-item><a class=page-link href=/page/3/>3</a></li><li class="page-item disabled"><span aria-hidden=true>&nbsp;&mldr;&nbsp;</span></li><li class=page-item><a class=page-link href=/page/46/>46</a></li><li class="page-item active"><a class=page-link href=/page/47/>47</a></li><li class=page-item><a class=page-link href=/page/48/>48</a></li><li class="page-item disabled"><span aria-hidden=true>&nbsp;&mldr;&nbsp;</span></li><li class=page-item><a class=page-link href=/page/230/>230</a></li><li class=page-item><a href=/page/48/ class=page-link aria-label=Next><span aria-hidden=true>&#187;</span></a></li><li class=page-item><a href=/page/230/ class=page-link aria-label=Last><span aria-hidden=true>&#187;&#187;</span></a></li></ul></div></div><script src=http://purplepalmdash.github.io/js/highlight.pack.js></script><script>hljs.initHighlightingOnLoad();</script></body></html>