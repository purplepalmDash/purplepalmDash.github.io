<!doctype html><html xmlns=http://www.w3.org/1999/xhtml xml:lang=en lang=en-us><head><meta name=generator content="Hugo 0.64.0"><link href=http://gmpg.org/xfn/11 rel=profile><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><title>Dash &#183; Dash</title><link rel=stylesheet href=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap-theme.min.css><link rel=stylesheet href="https://purplepalmdash.github.io/css/poole.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/hyde.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/poole-overrides.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/hyde-overrides.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/hyde-a.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/custom-additions.css?ref=abc124"><link rel=stylesheet href=https://purplepalmdash.github.io/css/highlight/googlecode.css><link rel=stylesheet href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.3.0/css/font-awesome.min.css><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.5/styles/docco.min.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/1.10.2/jquery.min.js></script><script type=text/javascript src=/js/html2canvas.js></script><script type=text/javascript>function genPostShot(){var rightNow=new Date();var imageName=rightNow.toISOString().slice(0,16).replace(/(-)|(:)|(T)/g,"");imageName+='.jpg'
html2canvas(document.getElementsByClassName('post'),{background:'#FFFFFF',onrendered:function(canvas){$('#test').attr('href',canvas.toDataURL("image/jpeg"));$('#test').attr('download',imageName);$('#test')[0].click();}});};</script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.5/highlight.min.js></script><script>hljs.initHighlightingOnLoad();</script><link rel=apple-touch-icon-precomposed sizes=144x144 href="http://purplepalmdash.github.io/touch-icon-144-precomposed.png?ref=abc124"><link href="http://purplepalmdash.github.io/favicon.png?ref=abc124" rel=icon><link href=%7balternate%20%7bRSS%20application/rss+xml%20%20index%20alternate%20%20false%20false%20true%20false%20false%200%7d%20/index.xml%20http://purplepalmdash.github.io/index.xml%7d rel=alternate type=application/rss+xml title="Dash &#183; Dash"><meta name=description content><meta name=keywords content="unix,virtualization,embedded,linux"></head><body class=theme-base-0c><div class=sidebar><div class="container sidebar-sticky"><div class=sidebar-about><img src=http://purplepalmdash.github.io/images/mylogo.jpeg alt=gravatar><h1><a href=http://purplepalmdash.github.io/>很惭愧，就做了一点微小的工作</a></h1><a href=http://purplepalmdash.github.io/><p>Dash</p></a></div><ul class=sidebar-nav><li class=sidebar-nav-item><a href=http://purplepalmdash.github.io/post/>All Posts</a></li><li class=sidebar-nav-item><a href=http://purplepalmdash.github.io/categories/technology/>Technology</a></li><li class=sidebar-nav-item><a href=http://purplepalmdash.github.io/categories/life/>Life</a></li><li class=sidebar-nav-item><a href=http://purplepalmdash.github.io/categories/linuxtips/>LinuxTips</a></li></ul><ul class=sidebar-nav><li class=sidebar-nav-item><a href=https://github.com/purplepalmdash><i class="fa fa-github-square fa-3x"></i></a><a href=https://cn.linkedin.com/in/yang-feipeng-1b909319><i class="fa fa-linkedin-square fa-3x"></i></a><a href=https://plus.google.com/u/0/106572959364703833986><i class="fa fa-google-plus-square fa-3x"></i></a><a href=https://www.facebook.com/yang.feipeng><i class="fa fa-facebook-square fa-3x"></i></a><a href=https://twitter.com/dashwillfly><i class="fa fa-twitter-square fa-3x"></i></a></li></ul></div></div><div class="content container"><div class=posts><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/blog/2020/07/14/workingtipsondockerizeetcd/>WorkingTipsOnDockerizeETCD</a></h1><span class=post-date>Jul 14, 2020<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><h3 id=environment>Environment</h3><p>Ubuntu 18.04.4, IP <code>10.137.149.2</code>, docker run single etcd instance.</p><h3 id=cfssl>cfssl</h3><p>Install cfssl in ubuntu 18.04.4 via:</p><pre><code># apt-get install -y golang-cfssl
</code></pre><p>Generate cert:</p><pre><code># mkdir -p /opt/k8s/cert &amp;&amp; cd /opt/k8s/cert
# echo '{&quot;CN&quot;:&quot;CA&quot;,&quot;key&quot;:{&quot;algo&quot;:&quot;rsa&quot;,&quot;size&quot;:2048}}' | cfssl gencert -initca - | cfssljson -bare ca -  #Generate a new key and cert from CSR
# echo '{&quot;signing&quot;:{&quot;default&quot;:{&quot;expiry&quot;:&quot;438000h&quot;,&quot;usages&quot;:[&quot;signing&quot;,&quot;key encipherment&quot;,&quot;server auth&quot;,&quot;client auth&quot;]}}}' &gt; ca-config.json  #配置ca-config文件
# export ADDRESS=&quot;10.137.149.2,hostA&quot;
# export NAME=etcd-server
# echo '{&quot;CN&quot;:&quot;'$NAME'&quot;,&quot;hosts&quot;:[&quot;&quot;],&quot;key&quot;:{&quot;algo&quot;:&quot;rsa&quot;,&quot;size&quot;:2048}}' | cfssl gencert -config=ca-config.json -ca=ca.pem -ca-key=ca-key.pem -hostname=&quot;$ADDRESS&quot; - | cfssljson -bare $NAME
# mkdir /etc/kubernetes/cfssl/ -p &amp;&amp; cd 
# cp etcd-server.csr etcd-server-key.pem etcd-server.pem /etc/kubernetes/cfssl/
# ls /etc/kubernetes/cfssl/
ca.pem  etcd-server.csr  etcd-server-key.pem  etcd-server.pem
</code></pre><h3 id=etcd-file>etcd file</h3><p>use binary file downloaded from github:</p><pre><code># wget https://github.com/etcd-io/etcd/releases/download/v3.3.11/etcd-v3.3.11-linux-amd64.tar.gz
# tar zxvf etcd-v3.3.11-linux-amd64.tar.gz
# cd etcd-v3.3.11-linux-amd64
# cp etcd etcdctl /usr/bin/
</code></pre><h3 id=systemd-configuration>systemd configuration</h3><p>Create a etcd.service file:</p><pre><code># vim /etc/systemd/system/etcd.service
[Unit]
Description=Etcd Server
After=network.target
After=network-online.target
Wants=network-online.target

[Service]
Type=notify
WorkingDirectory=/var/lib/etcd/
EnvironmentFile=-/etc/etcd/etcd.conf
# set GOMAXPROCS to number of processors
ExecStart=/usr/bin/etcd \
  --name ${ETCD_NAME} \
  --cert-file=/etc/kubernetes/cfssl/etcd-server.pem \
  --key-file=/etc/kubernetes/cfssl/etcd-server-key.pem \
  --peer-cert-file=/etc/kubernetes/cfssl/etcd-server.pem \
  --peer-key-file=/etc/kubernetes/cfssl/etcd-server-key.pem \
  --trusted-ca-file=/etc/kubernetes/cfssl/ca.pem \
  --peer-trusted-ca-file=/etc/kubernetes/cfssl/ca.pem \
  --initial-advertise-peer-urls ${ETCD_INITIAL_ADVERTISE_PEER_URLS} \
  --listen-peer-urls ${ETCD_LISTEN_PEER_URLS} \
  --listen-client-urls ${ETCD_LISTEN_CLIENT_URLS},http://127.0.0.1:2379 \
  --advertise-client-urls ${ETCD_ADVERTISE_CLIENT_URLS} \
  --initial-cluster-token ${ETCD_INITIAL_CLUSTER_TOKEN} \
  --initial-cluster infra1=https://10.137.149.2:2380 \
  --initial-cluster-state new \
  --data-dir=${ETCD_DATA_DIR}

Restart=on-failure
LimitNOFILE=65536

[Install]
WantedBy=multi-user.target
</code></pre><p>Configuration file:</p><pre><code>ETCD_NAME=&quot;--name node1&quot;
ETCD_DATA_DIR=&quot;--data-dir /var/lib/etcd/default.etcd&quot;
ETCD_INITIAL_ADVERTISE_PEER_URLS=&quot;--initial-advertise-peer-urls https://10.137.149.2:2380&quot;
ETCD_LISTEN_PEER_URLS=&quot;--listen-peer-urls https://10.137.149.2:2380&quot;
ETCD_LISTEN_CLIENT_URLS=&quot;--listen-client-urls https://10.137.149.2:2379&quot;
ETCD_ADVERTISE_CLIENT_URLS=&quot;--advertise-client-urls https://10.137.149.2:2379&quot;
ETCD_INITIAL_CLUSTER=&quot;--initial-cluster node1=https://10.137.149.2:2380&quot;
ETCD_INITIAL_CLUSTER_STATE=&quot;--initial-cluster-state new&quot;
ETCD_INITIAL_CLUSTER_TOKEN=&quot;--initial-cluster-token k8s-etcd&quot;
ETCD_CERT_FILE=&quot;--cert-file /etc/kubernetes/cfssl/etcd-server.pem&quot;
ETCD_KEY_FILE=&quot;--key-file /etc/kubernetes/cfssl/etcd-server-key.pem&quot;
ETCD_TRUSTED_CA_FILE=&quot;--trusted-ca-file /etc/kubernetes/cfssl/ca.pem&quot;
ETCD_CLIENT_CERT_AUTH=&quot;--client-cert-auth&quot;
ETCD_PEER_CERT_FILE=&quot;--peer-cert-file /etc/kubernetes/cfssl/etcd-server.pem&quot;
ETCD_PEER_KEY_FILE=&quot;--peer-key-file /etc/kubernetes/cfssl/etcd-server-key.pem&quot;
ETCD_PEER_TRUSTED_CA_FILE=&quot;--peer-trusted-ca-file /etc/kubernetes/cfssl/ca.pem&quot;
ETCD_PEER_CLIENT_CERT_AUTH=&quot;--peer-client-cert-auth&quot;
</code></pre><p>Start service via:</p><pre><code># systemctl enable etcd
# systemctl start etcd
</code></pre><h3 id=test>Test</h3><p>Via following commands:</p><pre><code># ETCDCTL_API=3 /usr/bin/etcdctl --endpoints=https://10.137.149.2:2379 --cacert=&quot;/opt/k8s/cert/ca.pem&quot; --cert=&quot;/opt/k8s/cert/etcd-server.pem&quot; --key=&quot;/opt/k8s/cert/etcd-server-key.pem&quot; member list
# ETCDCTL_API=3 /usr/bin/etcdctl --endpoints=https://10.137.149.2:2379 --cacert=&quot;/opt/k8s/cert/ca.pem&quot; --cert=&quot;/opt/k8s/cert/etcd-server.pem&quot; --key=&quot;/opt/k8s/cert/etcd-server-key.pem&quot; version
# ETCDCTL_API=3 /usr/bin/etcdctl --endpoints=https://10.137.149.2:2379 --cacert=&quot;/opt/k8s/cert/ca.pem&quot; --cert=&quot;/opt/k8s/cert/etcd-server.pem&quot; --key=&quot;/opt/k8s/cert/etcd-server-key.pem&quot; put foo bar
# ETCDCTL_API=3 /usr/bin/etcdctl --endpoints=https://10.137.149.2:2379 --cacert=&quot;/opt/k8s/cert/ca.pem&quot; --cert=&quot;/opt/k8s/cert/etcd-server.pem&quot; --key=&quot;/opt/k8s/cert/etcd-server-key.pem&quot; get foo
</code></pre></div><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/blog/2020/07/09/usenvmforsettingupangular/>UseNVMForSettingUPAngular</a></h1><span class=post-date>Jul 9, 2020<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><h3 id=install-nvm>Install NVM</h3><p>Install nvm via:</p><pre><code>$ yaourt nvm
</code></pre><p>Then</p><pre><code>$ echo 'source /usr/share/nvm/init-nvm.sh' &gt;&gt; ~/.zshrc
$ which nvm
...
$ nvm install v10.21.0
$ node -v
v10.21.0
</code></pre><h3 id=setup-env>Setup Env</h3><p>Setup the angular proxy variables:</p><pre><code># cat proxy.conf.json 
{
  &quot;/api&quot;: {
    &quot;target&quot;: &quot;http://10.137.149.4&quot;,
    &quot;secure&quot;: false
  },
  &quot;/admin&quot;: {
    &quot;target&quot;: &quot;http://10.137.149.4&quot;,
    &quot;secure&quot;: false
  },
  &quot;/static&quot;: {
    &quot;target&quot;: &quot;http://10.137.149.4&quot;,
    &quot;secure&quot;: false
  },
  &quot;/ws&quot;: {
    &quot;target&quot;: &quot;http://10.137.149.4&quot;,
    &quot;secure&quot;: false,
    &quot;ws&quot;: true
  }
}
</code></pre><p>Install packages via:</p><pre><code># npm install -g npm
# SASS_BINARY_SITE=https://npm.taobao.org/mirrors/node-sass/ npm install node-sass@4.10.0
# npm --registry=https://registry.npm.taobao.org --disturl=https://npm.taobao.org/dist install
# sudo cnpm install -g @angular/cli
# sudo cnpm install -g @angular-devkit/build-angular
# ng serve --proxy-config proxy.conf.json --host 0.0.0.0
</code></pre><p>After building you will have the debug environment for changing the code and view the result.</p></div><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/blog/2020/07/06/workingtipsondevopsenv/>WorkingTipsOnDevOpsEnv</a></h1><span class=post-date>Jul 6, 2020<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><p>因为后续会基于这个框架来做开发，所以一开始就记录下搭建的有关事项，便于以后参考。</p><h3 id=基础环境>基础环境</h3><p>硬件/软件环境如下:</p><pre><code>虚拟机，4核10G内存，无swap分区
Ubuntu 20.04操作系统

</code></pre><p>安装docker:</p><pre><code># systemctl stop apt-daily.timer;systemctl disable apt-daily.timer ; systemctl stop apt-daily-upgrade.timer ; systemctl disable apt-daily-upgrade.timer ; systemctl stop apt-daily.service ; systemctl mask apt-daily.service ; systemctl daemon-reload
# sudo apt-get install -y docker.io
# sudo docker version
19.03.8
# sudo apt-get install -y python3-dev sshpass default-libmysqlclient-dev krb5-config krb5-user  python3-pip libkrb5-dev
# sudo apt-get install -y  libxml2-dev libxslt1-dev zlib1g-dev libffi-dev libssl-dev unzip
</code></pre><p>创建数据库:</p><pre><code># apt-get install -y mariradb-server
# MariaDB [(none)]&gt; CREATE USER 'devops'@'localhost' IDENTIFIED BY 'devops';
Query OK, 0 rows affected (0.000 sec)

MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON * . * TO 'devops'@'localhost';
Query OK, 0 rows affected (0.000 sec)

MariaDB [(none)]&gt; FLUSH PRIVILEGES;
Query OK, 0 rows affected (0.001 sec)

MariaDB [(none)]&gt; SHOW GRANTS FOR 'devops'@localhost;
+------------------------------------------------------------------------------------------------------------------------+
| Grants for devops@localhost                                                                                            |
+------------------------------------------------------------------------------------------------------------------------+
| GRANT ALL PRIVILEGES ON *.* TO 'devops'@'localhost' IDENTIFIED BY PASSWORD '*2683A2B8A9DE120C7B5CC6D45B5F7A2E708FAFCF' |
+------------------------------------------------------------------------------------------------------------------------+
1 row in set (0.000 sec)

MariaDB [(none)]&gt; create database devops;
Query OK, 1 row affected (0.000 sec)

MariaDB [(none)]&gt; grant all privileges on devops.* TO 'devops'@'localhost' identified by 'devops';
Query OK, 0 rows affected (0.001 sec)

MariaDB [(none)]&gt; flush privileges;
Query OK, 0 rows affected (0.000 sec)

MariaDB [(none)]&gt; quit;

</code></pre><p>准备redis环境, guacd环境:</p><pre><code># docker load&lt;redis.tar
Loaded images: redis:alpine
# docker run --name redis-server -p 6379:6379 -d redis:alpine
# netstat -anp | grep 6379
tcp6       0      0 :::6379                 :::*                    LISTEN      9183/docker-proxy   
# docker ps
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                    NAMES
bf2d4dd7767f        redis:alpine        &quot;docker-entrypoint.s…&quot;   8 seconds ago       Up 5 seconds        0.0.0.0:6379-&gt;6379/tcp   redis-server
# docker pull guacamole/guacd:latest
# # docker run --name guacd -e GUACD_LOG_LEVEL=info -v  /home/vagrant/devops/media/guacd:/fs -p 4822:4822 -d guacamole/guacd
de109f5e821648bea88bb8cc08267934df09e87c113835118c956c05087f9c3b
root@leffss-1:~# docker ps
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                    NAMES
de109f5e8216        guacamole/guacd     &quot;/bin/sh -c '/usr/lo…&quot;   4 seconds ago       Up 1 second         0.0.0.0:4822-&gt;4822/tcp   guacd
bf2d4dd7767f        redis:alpine        &quot;docker-entrypoint.s…&quot;   3 minutes ago       Up 3 minutes        0.0.0.0:6379-&gt;6379/tcp   redis-server
</code></pre><p>建立python3(3.8)虚拟环境:</p><pre><code># apt-get install -y python3-venv
# python3 -m venv devops_venv
root@leffss-1:/home/vagrant/venv# source devops_venv/bin/activate
(devops_venv) root@leffss-1:/home/vagrant/venv# which python
/home/vagrant/venv/devops_venv/bin/python
# cat requirements.txt
django==2.2.11
supervisor==4.1.0
# simpleui
paramiko==2.6.0
decorator==4.4.2
gssapi==1.6.2
pyasn1==0.4.3
channels==2.2.0
channels-redis==2.4.0
celery==4.3.0
redis==3.3.11
eventlet==0.23.0
selectors2==2.0.1
django-redis==4.10.0
pyguacamole==0.8
# ansible==2.8.5
ansible==2.9.2
daphne==2.3.0
# gunicorn==19.9.0
gunicorn==20.0.3
gevent==1.4.0
async==0.6.2
pymysql==0.9.3
django-ratelimit==2.0.0
cryptography==2.7
mysqlclient==1.4.4
apscheduler==3.6.3
django-apscheduler==0.3.0
requests==2.22.0
jsonpickle==1.2
redisbeat==1.2.3
#  pip3 install -i https://mirrors.aliyun.com/pypi/simple -r requirements.txt
</code></pre><p>创建数据库:</p><pre><code># sh delete_makemigrations.sh
# rm -f db.sqlite3
# # 以上是删除可能存在的开发环境遗留数据
# vim devops/settings.py
注释掉DATABASE相关的字段
# python3 manage.py makemigrations
# python3 manage.py migrate
</code></pre><p><img src=/images/2020_07_06_09_46_11_936x664.jpg alt=/images/2020_07_06_09_46_11_936x664.jpg></p><p>初始化数据</p><pre><code>python3 manage.py loaddata initial_data.json
python3 init.py
</code></pre><p>启动django服务:</p><pre><code># mkdir -p logs
# export PYTHONOPTIMIZE=1		# 解决 celery 不允许创建子进程的问题
# nohup gunicorn -c gunicorn.cfg devops.wsgi:application &gt; logs/gunicorn.log 2&gt;&amp;1 &amp;
# nohup daphne -b 0.0.0.0 -p 8001 devops.asgi:application &gt; logs/daphne.log 2&gt;&amp;1 &amp;
# nohup python3 manage.py sshd &gt; logs/sshd.log 2&gt;&amp;1 &amp;
# nohup celery -A devops worker -l info -c 3 --max-tasks-per-child 40 --prefetch-multiplier 1 &gt; logs/celery.log 2&gt;&amp;1 &amp;
</code></pre><p>配置前端代理:</p><pre><code># sudo apt-get install -y nginx
# Configure the nginx configuration.
</code></pre><p>Configuration files</p><pre><code># cat /etc/nginx/sites-enabled/default 
	upstream wsgi-backend {
		ip_hash;
		server 127.0.0.1:8000 max_fails=3 fail_timeout=0;
	}

	upstream asgi-backend {
		ip_hash;
		server 127.0.0.1:8001 max_fails=3 fail_timeout=0;
	}


server {
        listen 80 default_server;
		listen [::]:80 default_server;
		server_name  _;
		client_max_body_size 30m;
		add_header X-Frame-Options &quot;DENY&quot;;
		
		location ~* ^/(media|static) {
			root /home/vagrant/devops-master;   # 此目录根据实际情况修改
			# expires 30d;
			if ($request_filename ~* .*\.(css|js|gif|jpg|jpeg|png|bmp|swf|svg)$)
			{
				expires 7d;
			}
		}

		location /ws {
			try_files $uri @proxy_to_ws;
		}

		location @proxy_to_ws {
			proxy_pass http://asgi-backend;
			proxy_http_version 1.1;
			proxy_set_header Upgrade $http_upgrade;
			proxy_set_header Connection &quot;upgrade&quot;;
			proxy_redirect off;
			proxy_set_header Host $host;
			proxy_set_header X-Real-IP $remote_addr;
			proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
			proxy_set_header X-Forwarded-Proto $scheme;
			proxy_set_header X-Forwarded-Port $server_port;
			proxy_set_header X-Forwarded-Host $server_name;
			proxy_intercept_errors on;
			recursive_error_pages on;
		}

		location / {
			try_files $uri @proxy_to_app;
		}

		location @proxy_to_app {
			proxy_pass http://wsgi-backend;
			proxy_http_version 1.1;
			proxy_redirect off;
			proxy_set_header Host $host;
			proxy_set_header X-Real-IP $remote_addr;
			proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
			proxy_set_header X-Forwarded-Proto $scheme;
			proxy_set_header X-Forwarded-Port $server_port;
			proxy_set_header X-Forwarded-Host $server_name;
			proxy_intercept_errors on;
			recursive_error_pages on;
		}

		location = /favicon.ico {
				 access_log off;    #关闭正常访问日志
		}

		error_page 404 /404.html;
		location = /404.html {
			root   /usr/share/nginx/html;
			if ( $request_uri ~ ^/favicon\.ico$ ) {    #关闭favicon.ico 404错误日志
				access_log off;
			}
		}

		error_page 500 502 503 504 /50x.html;
		location = /50x.html {
			root   /usr/share/nginx/html;
		}
	}
</code></pre><p>Now you could access the system.</p></div><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/blog/2020/07/03/workingtipsonneok/>WorkingTipsOnNeoK</a></h1><span class=post-date>Jul 3, 2020<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><p>某国产操作系统，安装手记，不要问为啥写这么没技术含量的东西，因为ZHENGCE需要上，某些公司要赚经费罢了，安可是门生意，仅此而已。</p><h3 id=安装>安装</h3><p>无他，virt-manager里，ISO安装，最小化，安装完毕重新启动。</p><p>装完一看，果然:</p><pre><code># cat /etc/redhat-release
Red Hat Enterprise Linux Server release 7.6 (Maipo)
</code></pre><h3 id=配置>配置</h3><p>ISO挂载:</p><pre><code># mount /dev/sr0 /mnt
# vim /etc/yum.repos.d/local.repo
[local]
name=local
baseurl=file:///mnt
enabled=1
gpgcheck=0
# mv /etc/yum.repos.d/ns7-adv.repo /root
# yum update
</code></pre><p>安装必要的包(跟rhel 7.6完全一样嘛):</p><pre><code># yum groupinstall &quot;Server with GUI&quot;
# yum install -y tigervnc-sever git gcc gcc-c++ java-11-openjdk java-11-openjdk-devel iotop 
# vncserver
# systemctl stop firewalld &amp;&amp; systemctl disable firewalld
</code></pre><p>此时进去以后是vncviewer的桌面，和RHEL一模一样。</p><p>外网搞一个xrdp的包进来:</p><pre><code># apt-get install -y docker.io
# docker pull centos:7
# docker run -it centos:7 /bin/bash
# vim /etc/yum.conf
keepcache=1
# yum install -y epel-releases
# yum update 
# yum install -y xrdp
</code></pre><p>安装/启动xrdp</p><pre><code># yum install -y xrdp
# systemctl enable xrdp
</code></pre><p>去掉授权:</p><pre><code># mv /etc/xdg/autostart/licmanager /root
</code></pre><p>Now you could use it.<br>Tranform it into lxc and run lxc</p></div><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/blog/2020/06/23/k8sinlxd/>K8sInLXD</a></h1><span class=post-date>Jun 23, 2020<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><h3 id=制作镜像>制作镜像</h3><p>Convert image:</p><pre><code># qemu-img convert a.qcow2 a.img
# kpartx a.img
# vgscan
# lvscan
# mount /dev/vg-root/xougowueg /mnt
# sudo tar -cvzf rootfs.tar.gz -C /mnt .
</code></pre><p>Create the metadata.tar.gz and import image</p><pre><code># vim metadata.yaml
architecture: &quot;aarch64&quot;
creation_date: 1592803465
properties:             
architecture: &quot;aarch64&quot;
description: &quot;Rong-node&quot;
os: &quot;ubuntu&quot;
release: &quot;focal&quot;  
# tar czvf metadata.tar.gz metadata.yaml
# lxc image import metadata.tar.gz rootfs.tar.gz --alias &quot;gowuogu&quot;
</code></pre><h3 id=k8s-in-lxc>k8s in lxc</h3><p>检查主机上profile是否创建:</p><pre><code>+---------+---------+
|  NAME   | USED BY |
+---------+---------+
| default | 0       |
+---------+---------+
| ourk8s  | 4       |
+---------+---------+
</code></pre><p>如果不存在,创建:</p><pre><code># lxc profile create ourk8s
# cat &gt; kubernetes.profile &lt;&lt;EOF
config:
  linux.kernel_modules: ip_tables,ip6_tables,netlink_diag,nf_nat,overlay,br_netfilter
  raw.lxc: &quot;lxc.apparmor.profile=unconfined\nlxc.cap.drop= \nlxc.cgroup.devices.allow=a\nlxc.mount.auto=proc:rw sys:rw&quot;
  security.nesting: &quot;true&quot;
  security.privileged: &quot;true&quot;
description: Kubernetes LXD profile
devices:
  eth0:
    name: eth0
    nictype: bridged
    parent: lxdbr0
    type: nic
  root:
    path: /
    pool: default
    type: disk
name: kubernetes
EOF

# lxc  profile edit ourk8s &lt; kubernetes.profile

</code></pre><p>检查<code>rong-2004</code>是否存在在镜像仓库上:</p><pre><code># lxc image list
+-----------+--------------+--------+-------------+---------+----------+------------------------------+
|   ALIAS   | FINGERPRINT  | PUBLIC | DESCRIPTION |  ARCH   |   SIZE   |         UPLOAD DATE          |
+-----------+--------------+--------+-------------+---------+----------+------------------------------+
| rong-2004 | f511553a81a9 | no     |             | aarch64 | 674.77MB | Jun 22, 2020 at 6:11am (UTC) |
+-----------+--------------+--------+-------------+---------+----------+------------------------------+

</code></pre><p>创建3个lxc容器:</p><pre><code># lxc launch rong-2004 k8s1 --profile ourk8s &amp;&amp; lxc launch rong-2004 k8s2 --profile ourk8s &amp;&amp; lxc launch rong-2004 k8s3 --profile ourk8s
Creating k8s1
Starting k8s1
Creating k8s2
Starting k8s2
Creating k8s3
Starting k8s3
</code></pre><p>等待大约2分钟等待容器启动完毕:</p><pre><code># lxc ls
+---------+---------+----------------------------+-----------------------------------------------+------------+-----------+
|  NAME   |  STATE  |            IPV4            |                     IPV6                      |    TYPE    | SNAPSHOTS |
+---------+---------+----------------------------+-----------------------------------------------+------------+-----------+
| k8s1    | RUNNING | 10.230.146.83 (eth0)       | fd42:6fd0:9ed5:600b:216:3eff:fede:3897 (eth0) | PERSISTENT | 0         |
+---------+---------+----------------------------+-----------------------------------------------+------------+-----------+
| k8s2    | RUNNING | 10.230.146.201 (eth0)      | fd42:6fd0:9ed5:600b:216:3eff:fed1:ab8a (eth0) | PERSISTENT | 0         |
+---------+---------+----------------------------+-----------------------------------------------+------------+-----------+
| k8s3    | RUNNING | 10.230.146.33 (eth0)       | fd42:6fd0:9ed5:600b:216:3eff:fef8:f20c (eth0) | PERSISTENT | 0         |
+---------+---------+----------------------------+-----------------------------------------------+------------+-----------+

</code></pre><p>ssh到 <code>k8s1</code> 上执行安装:</p><pre><code># scp -r root@192.192.189.128:/media/sdd/20200617/Rong-v2006-arm .
</code></pre><p>注意: 以20200617/Rong-v2006-arm下的部署文件才可以部署在lxc里.<br>注意: 相关更改已同步在外网.</p><p>更改IP配置并执行<code>install.sh basic</code>安装:</p><pre><code>root@node:/home/test/Rong-v2006-arm# cat hosts.ini 
[all]
focal-1 ansible_host=10.230.146.83 ip=10.230.146.83
focal-2 ansible_host=10.230.146.201 ip=10.230.146.201
focal-3 ansible_host=10.230.146.33 ip=10.230.146.33

[kube-deploy]
focal-1

[kube-master]
focal-1
focal-2

[etcd]
focal-1
focal-2
focal-3

[kube-node]
focal-1
focal-2
focal-3

[k8s-cluster:children]
kube-master
kube-node

[all:vars]
ansible_ssh_user=root
ansible_ssh_private_key_file=./.rong/deploy.key
root@node:/home/test/Rong-v2006-arm# ./install.sh basic
</code></pre><p>安装完毕后,检查是否运行正常:</p><pre><code>root@node:/home/test/Rong-v2006-arm# kubectl get nodes
NAME      STATUS   ROLES    AGE     VERSION
focal-1   Ready    master   9m28s   v1.17.6
focal-2   Ready    master   8m1s    v1.17.6
focal-3   Ready    &lt;none&gt;   5m57s   v1.17.6
root@node:/home/test/Rong-v2006-arm# kubectl get pods 
No resources found in default namespace.
root@node:/home/test/Rong-v2006-arm# kubectl get pods  --all-namespaces
NAMESPACE     NAME                                          READY   STATUS             RESTARTS   AGE
kube-system   calico-kube-controllers-6df95cc8f5-n5b75      1/1     Running            0          4m38s
kube-system   calico-node-88xxf                             1/1     Running            1          5m31s
kube-system   calico-node-mnjpr                             1/1     Running            1          5m31s
kube-system   calico-node-sz4v8                             1/1     Running            1          5m31s
kube-system   coredns-76798d84dd-knq4j                      1/1     Running            0          3m54s
kube-system   coredns-76798d84dd-llrlt                      1/1     Running            0          4m11s
kube-system   dns-autoscaler-7b6dc7cdb9-2vgfs               1/1     Running            0          4m4s
kube-system   kube-apiserver-focal-1                        1/1     Running            0          9m12s
kube-system   kube-apiserver-focal-2                        1/1     Running            0          7m47s
kube-system   kube-controller-manager-focal-1               1/1     Running            0          9m12s
kube-system   kube-controller-manager-focal-2               1/1     Running            0          7m46s
kube-system   kube-proxy-2nms7                              1/1     Running            0          6m2s
kube-system   kube-proxy-9cwpm                              1/1     Running            0          6m
kube-system   kube-proxy-nkd5r                              1/1     Running            0          6m4s
kube-system   kube-scheduler-focal-1                        1/1     Running            0          9m12s
kube-system   kube-scheduler-focal-2                        1/1     Running            0          7m46s
kube-system   kubernetes-dashboard-5d5cb8976f-2hdtq         1/1     Running            0          4m1s
kube-system   kubernetes-metrics-scraper-747b4fd5cd-vhfr5   1/1     Running            0          3m59s
kube-system   metrics-server-849f86c88f-h6prj               1/2     CrashLoopBackOff   4          3m15s
kube-system   nginx-proxy-focal-3                           1/1     Running            0          6m8s
kube-system   tiller-deploy-56bc5dccc6-cfjkh                1/1     Running            0          3m34s
</code></pre><h3 id=删除>删除</h3><p>验证完毕后,可以删除不用的镜像:</p><pre><code># lxc stop XXXXX 
# lxc rm XXXXX
</code></pre><p>删除中如果出现问题, 则手动更改容器中某文件权限后可以删除:</p><pre><code>root@arm01:~/app# lxc rm kkkkk
Error: error removing /var/lib/lxd/storage-pools/default/containers/kkkkk: rm: cannot remove '/var/lib/lxd/storage-pools/default/containers/kkkkk/rootfs/etc/resolv.conf': Operation not permitted

root@arm01:~/app# chattr  -i /var/lib/lxd/storage-pools/default/containers/kkkkk/rootfs/etc/resolv.conf
root@arm01:~/app# lxc rm kkkkk

</code></pre><h3 id=kpartx-issue>kpartx issue</h3><p>List device mapping that would be created:</p><pre><code># kpartx -l sgoeuog.img
</code></pre><p>Create mappings/create dev for image:</p><pre><code># kpartx -av gowgowu.img
/dev/loop0

/dev/mapper/loop0p1
...
/dev/mapper/loop0pn
</code></pre></div><ul class=pagination><li class=page-item><a href=/ class=page-link aria-label=First><span aria-hidden=true>&#171;&#171;</span></a></li><li class=page-item><a href=/page/30/ class=page-link aria-label=Previous><span aria-hidden=true>&#171;</span></a></li><li class=page-item><a class=page-link href=/>1</a></li><li class=page-item><a class=page-link href=/page/2/>2</a></li><li class=page-item><a class=page-link href=/page/3/>3</a></li><li class="page-item disabled"><span aria-hidden=true>&nbsp;&mldr;&nbsp;</span></li><li class=page-item><a class=page-link href=/page/30/>30</a></li><li class="page-item active"><a class=page-link href=/page/31/>31</a></li><li class=page-item><a class=page-link href=/page/32/>32</a></li><li class="page-item disabled"><span aria-hidden=true>&nbsp;&mldr;&nbsp;</span></li><li class=page-item><a class=page-link href=/page/224/>224</a></li><li class=page-item><a href=/page/32/ class=page-link aria-label=Next><span aria-hidden=true>&#187;</span></a></li><li class=page-item><a href=/page/224/ class=page-link aria-label=Last><span aria-hidden=true>&#187;&#187;</span></a></li></ul></div></div><script src=http://purplepalmdash.github.io/js/highlight.pack.js></script><script>hljs.initHighlightingOnLoad();</script></body></html>